Using cuda device
Epoch 1
-------------------------------
Training loss: 3.630248  [16/3680]
Training loss: 3.366400  [1616/3680]
Training loss: 3.308069  [3216/3680]
Training accuracy: 20.49 %
Validation loss: 3.119017
Validation accuracy: 23.58% 

Epoch 2
-------------------------------
Training loss: 3.079093  [16/3680]
Training loss: 2.990846  [1616/3680]
Training loss: 2.794190  [3216/3680]
Training accuracy: 48.15 %
Validation loss: 2.617726
Validation accuracy: 51.36% 

Epoch 3
-------------------------------
Training loss: 2.782391  [16/3680]
Training loss: 2.687042  [1616/3680]
Training loss: 2.639544  [3216/3680]
Training accuracy: 63.97 %
Validation loss: 2.211528
Validation accuracy: 67.74% 

Epoch 4
-------------------------------
Training loss: 1.998755  [16/3680]
Training loss: 2.368526  [1616/3680]
Training loss: 1.885126  [3216/3680]
Training accuracy: 71.01 %
Validation loss: 1.890538
Validation accuracy: 73.74% 

Epoch 5
-------------------------------
Training loss: 1.956251  [16/3680]
Training loss: 1.759344  [1616/3680]
Training loss: 1.764932  [3216/3680]
Training accuracy: 77.15 %
Validation loss: 1.640518
Validation accuracy: 78.00% 

Epoch 6
-------------------------------
Training loss: 1.888342  [16/3680]
Training loss: 1.692232  [1616/3680]
Training loss: 1.662617  [3216/3680]
Training accuracy: 80.33 %
Validation loss: 1.426088
Validation accuracy: 79.86% 

Epoch 7
-------------------------------
Training loss: 1.300367  [16/3680]
Training loss: 1.350937  [1616/3680]
Training loss: 1.279227  [3216/3680]
Training accuracy: 82.58 %
Validation loss: 1.262407
Validation accuracy: 81.66% 

Epoch 8
-------------------------------
Training loss: 1.172108  [16/3680]
Training loss: 1.233964  [1616/3680]
Training loss: 1.701845  [3216/3680]
Training accuracy: 83.78 %
Validation loss: 1.156409
Validation accuracy: 83.46% 

Epoch 9
-------------------------------
Training loss: 1.285541  [16/3680]
Training loss: 1.048786  [1616/3680]
Training loss: 0.892798  [3216/3680]
Training accuracy: 84.38 %
Validation loss: 1.026609
Validation accuracy: 83.90% 

Epoch 10
-------------------------------
Training loss: 1.064810  [16/3680]
Training loss: 1.163350  [1616/3680]
Training loss: 1.395278  [3216/3680]
Training accuracy: 85.76 %
Validation loss: 0.957572
Validation accuracy: 84.72% 

Epoch 11
-------------------------------
Training loss: 1.236105  [16/3680]
Training loss: 0.916062  [1616/3680]
Training loss: 1.144769  [3216/3680]
Training accuracy: 86.06 %
Validation loss: 0.900806
Validation accuracy: 85.10% 

Epoch 12
-------------------------------
Training loss: 0.848937  [16/3680]
Training loss: 0.761136  [1616/3680]
Training loss: 1.087222  [3216/3680]
Training accuracy: 86.09 %
Validation loss: 0.833891
Validation accuracy: 85.43% 

Epoch 13
-------------------------------
Training loss: 1.072548  [16/3680]
Training loss: 0.957129  [1616/3680]
Training loss: 1.049269  [3216/3680]
Training accuracy: 87.42 %
Validation loss: 0.793828
Validation accuracy: 85.92% 

Epoch 14
-------------------------------
Training loss: 0.707736  [16/3680]
Training loss: 0.780452  [1616/3680]
Training loss: 0.784722  [3216/3680]
Training accuracy: 87.15 %
Validation loss: 0.750992
Validation accuracy: 85.70% 

Epoch 15
-------------------------------
Training loss: 0.780075  [16/3680]
Training loss: 0.781418  [1616/3680]
Training loss: 1.029925  [3216/3680]
Training accuracy: 87.53 %
Validation loss: 0.733914
Validation accuracy: 85.92% 

Epoch 16
-------------------------------
Training loss: 0.840473  [16/3680]
Training loss: 0.731374  [1616/3680]
Training loss: 0.694656  [3216/3680]
Training accuracy: 87.77 %
Validation loss: 0.690722
Validation accuracy: 85.92% 

Epoch 17
-------------------------------
Training loss: 0.824466  [16/3680]
Training loss: 0.709113  [1616/3680]
Training loss: 0.815284  [3216/3680]
Training accuracy: 88.12 %
Validation loss: 0.681084
Validation accuracy: 86.08% 

Epoch 18
-------------------------------
Training loss: 0.635950  [16/3680]
Training loss: 0.677584  [1616/3680]
Training loss: 0.602479  [3216/3680]
Training accuracy: 88.53 %
Validation loss: 0.649158
Validation accuracy: 86.24% 

Epoch 19
-------------------------------
Training loss: 0.544730  [16/3680]
Training loss: 0.859855  [1616/3680]
Training loss: 0.787062  [3216/3680]
Training accuracy: 88.80 %
Validation loss: 0.641557
Validation accuracy: 86.79% 

Epoch 20
-------------------------------
Training loss: 0.512984  [16/3680]
Training loss: 0.593255  [1616/3680]
Training loss: 0.696419  [3216/3680]
Training accuracy: 89.02 %
Validation loss: 0.619116
Validation accuracy: 87.17% 

Epoch 21
-------------------------------
Training loss: 0.820661  [16/3680]
Training loss: 0.735017  [1616/3680]
Training loss: 0.643966  [3216/3680]
Training accuracy: 89.10 %
Validation loss: 0.603543
Validation accuracy: 87.01% 

Epoch 22
-------------------------------
Training loss: 0.994332  [16/3680]
Training loss: 0.564102  [1616/3680]
Training loss: 0.609691  [3216/3680]
Training accuracy: 89.24 %
Validation loss: 0.575816
Validation accuracy: 87.45% 

Epoch 23
-------------------------------
Training loss: 0.380021  [16/3680]
Training loss: 0.608648  [1616/3680]
Training loss: 0.508701  [3216/3680]
Training accuracy: 88.72 %
Validation loss: 0.567985
Validation accuracy: 87.34% 

Epoch 24
-------------------------------
Training loss: 0.591473  [16/3680]
Training loss: 0.452014  [1616/3680]
Training loss: 0.534089  [3216/3680]
Training accuracy: 89.13 %
Validation loss: 0.550492
Validation accuracy: 87.28% 

Epoch 25
-------------------------------
Training loss: 0.553413  [16/3680]
Training loss: 0.702509  [1616/3680]
Training loss: 0.693049  [3216/3680]
Training accuracy: 89.57 %
Validation loss: 0.544726
Validation accuracy: 87.72% 

Epoch 26
-------------------------------
Training loss: 0.568660  [16/3680]
Training loss: 0.645868  [1616/3680]
Training loss: 1.107564  [3216/3680]
Training accuracy: 89.65 %
Validation loss: 0.536543
Validation accuracy: 87.66% 

Epoch 27
-------------------------------
Training loss: 0.409805  [16/3680]
Training loss: 0.376580  [1616/3680]
Training loss: 0.612796  [3216/3680]
Training accuracy: 89.81 %
Validation loss: 0.533782
Validation accuracy: 87.50% 

Epoch 28
-------------------------------
Training loss: 0.676781  [16/3680]
Training loss: 0.593978  [1616/3680]
Training loss: 0.735260  [3216/3680]
Training accuracy: 89.95 %
Validation loss: 0.524007
Validation accuracy: 87.88% 

Epoch 29
-------------------------------
Training loss: 0.630179  [16/3680]
Training loss: 0.684585  [1616/3680]
Training loss: 0.533889  [3216/3680]
Training accuracy: 89.84 %
Validation loss: 0.506215
Validation accuracy: 88.05% 

Epoch 30
-------------------------------
Training loss: 0.467623  [16/3680]
Training loss: 0.453700  [1616/3680]
Training loss: 0.434896  [3216/3680]
Training accuracy: 90.65 %
Validation loss: 0.519285
Validation accuracy: 88.05% 

Epoch 31
-------------------------------
Training loss: 0.466560  [16/3680]
Training loss: 0.367047  [1616/3680]
Training loss: 0.504012  [3216/3680]
Training accuracy: 90.35 %
Validation loss: 0.495549
Validation accuracy: 87.83% 

Epoch 32
-------------------------------
Training loss: 0.450925  [16/3680]
Training loss: 0.680772  [1616/3680]
Training loss: 0.976831  [3216/3680]
Training accuracy: 90.03 %
Validation loss: 0.487515
Validation accuracy: 88.76% 

Epoch 33
-------------------------------
Training loss: 0.598355  [16/3680]
Training loss: 0.596288  [1616/3680]
Training loss: 0.461826  [3216/3680]
Training accuracy: 90.68 %
Validation loss: 0.486384
Validation accuracy: 87.88% 

Epoch 34
-------------------------------
Training loss: 0.340312  [16/3680]
Training loss: 0.493017  [1616/3680]
Training loss: 0.562432  [3216/3680]
Training accuracy: 90.71 %
Validation loss: 0.474233
Validation accuracy: 88.43% 

Epoch 35
-------------------------------
Training loss: 0.357180  [16/3680]
Training loss: 0.608437  [1616/3680]
Training loss: 0.607429  [3216/3680]
Training accuracy: 90.82 %
Validation loss: 0.475360
Validation accuracy: 88.37% 

Epoch 36
-------------------------------
Training loss: 0.645867  [16/3680]
Training loss: 0.306590  [1616/3680]
Training loss: 0.456888  [3216/3680]
Training accuracy: 90.27 %
Validation loss: 0.475152
Validation accuracy: 88.59% 

Epoch 37
-------------------------------
Training loss: 0.308313  [16/3680]
Training loss: 0.340434  [1616/3680]
Training loss: 0.374082  [3216/3680]
Training accuracy: 90.62 %
Validation loss: 0.462807
Validation accuracy: 88.48% 

Early stopping
Done!

Elapsed time: 1977.3114564418793 seconds

                         precision    recall  f1-score   support

             Abyssinian       0.78      0.78      0.78        49
       American Bulldog       0.78      0.90      0.83        50
  American pitbull terr       0.79      0.60      0.68        50
           Basset hound       0.94      0.96      0.95        50
                 Beagle       0.92      0.92      0.92        50
                 Bengal       0.63      0.86      0.73        50
                 Birman       0.79      0.76      0.78        50
                 Bombay       0.81      0.95      0.88        44
                  Boxer       0.78      0.86      0.82        50
      British Shorthair       0.85      0.78      0.81        50
              Chihuahua       0.91      0.86      0.89        50
           Egyptian Mau       0.90      0.76      0.82        49
 English cocker spaniel       0.90      0.94      0.92        50
         English setter       0.94      0.90      0.92        50
     German shorthaired       0.85      1.00      0.92        50
         Great pyrenees       0.96      1.00      0.98        50
               Havanese       0.89      0.94      0.91        50
          Japanese chin       0.98      0.94      0.96        50
               Keeshond       0.96      1.00      0.98        50
             Leonberger       1.00      0.98      0.99        50
             Maine Coon       0.82      0.72      0.77        50
     Miniature pinscher       0.94      0.90      0.92        50
           Newfoundland       1.00      1.00      1.00        50
                Persian       0.84      0.82      0.83        50
             Pomeranian       0.98      0.92      0.95        50
                    Pug       0.98      0.92      0.95        50
                Ragdoll       0.84      0.76      0.80        50
           Russian blue       0.80      0.70      0.74        50
          Saint bernard       0.96      0.96      0.96        50
                Samoyed       0.94      1.00      0.97        50
       Scottish terrier       0.91      0.98      0.94        50
              Shiba inu       0.91      0.96      0.93        50
                Siamese       0.88      0.88      0.88        50
                 Sphynx       0.85      0.92      0.88        50
Staffordshire bull terr       0.66      0.60      0.63        45
        Wheaten terrier       0.98      0.86      0.91        50
      Yorkshire terrier       0.94      0.90      0.92        50

               accuracy                           0.88      1837
              macro avg       0.88      0.88      0.88      1837
           weighted avg       0.88      0.88      0.88      1837

Test accuracy: 0.8786064235166031
