Downloading https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz to ../../../../../../work3/s226536/datasets/oxford-iiit-pet/images.tar.gz
Extracting ../../../../../../work3/s226536/datasets/oxford-iiit-pet/images.tar.gz to ../../../../../../work3/s226536/datasets/oxford-iiit-pet
Downloading https://thor.robots.ox.ac.uk/datasets/pets/annotations.tar.gz to ../../../../../../work3/s226536/datasets/oxford-iiit-pet/annotations.tar.gz
Extracting ../../../../../../work3/s226536/datasets/oxford-iiit-pet/annotations.tar.gz to ../../../../../../work3/s226536/datasets/oxford-iiit-pet
Using custom data augmentation
Using cuda device
Epoch 1
-------------------------------
Training loss: 3.835501  [16/3680]
Training loss: 3.238032  [1616/3680]
Training loss: 3.079531  [3216/3680]
Training accuracy: 22.34 %
Validation loss: 3.116284
Validation accuracy: 24.18% 

Epoch 2
-------------------------------
Training loss: 3.253985  [16/3680]
Training loss: 3.291605  [1616/3680]
Training loss: 2.922950  [3216/3680]
Training accuracy: 42.66 %
Validation loss: 2.682408
Validation accuracy: 45.25% 

Epoch 3
-------------------------------
Training loss: 2.756421  [16/3680]
Training loss: 2.658915  [1616/3680]
Training loss: 2.448538  [3216/3680]
Training accuracy: 57.04 %
Validation loss: 2.303891
Validation accuracy: 60.48% 

Epoch 4
-------------------------------
Training loss: 2.321766  [16/3680]
Training loss: 2.065181  [1616/3680]
Training loss: 2.260624  [3216/3680]
Training accuracy: 64.73 %
Validation loss: 2.006401
Validation accuracy: 69.92% 

Epoch 5
-------------------------------
Training loss: 2.212747  [16/3680]
Training loss: 1.754548  [1616/3680]
Training loss: 2.201855  [3216/3680]
Training accuracy: 70.60 %
Validation loss: 1.770519
Validation accuracy: 75.22% 

Epoch 6
-------------------------------
Training loss: 1.997370  [16/3680]
Training loss: 2.137700  [1616/3680]
Training loss: 1.792937  [3216/3680]
Training accuracy: 73.23 %
Validation loss: 1.548972
Validation accuracy: 78.06% 

Epoch 7
-------------------------------
Training loss: 1.545147  [16/3680]
Training loss: 1.393926  [1616/3680]
Training loss: 1.609459  [3216/3680]
Training accuracy: 75.00 %
Validation loss: 1.405314
Validation accuracy: 80.68% 

Epoch 8
-------------------------------
Training loss: 1.885679  [16/3680]
Training loss: 1.677703  [1616/3680]
Training loss: 1.552331  [3216/3680]
Training accuracy: 78.51 %
Validation loss: 1.253694
Validation accuracy: 81.39% 

Epoch 9
-------------------------------
Training loss: 1.543739  [16/3680]
Training loss: 1.513697  [1616/3680]
Training loss: 1.249088  [3216/3680]
Training accuracy: 79.10 %
Validation loss: 1.154045
Validation accuracy: 82.91% 

Epoch 10
-------------------------------
Training loss: 1.517821  [16/3680]
Training loss: 1.144681  [1616/3680]
Training loss: 1.482211  [3216/3680]
Training accuracy: 79.05 %
Validation loss: 1.078898
Validation accuracy: 83.24% 

Epoch 11
-------------------------------
Training loss: 0.993579  [16/3680]
Training loss: 1.131362  [1616/3680]
Training loss: 1.676092  [3216/3680]
Training accuracy: 80.98 %
Validation loss: 1.003087
Validation accuracy: 84.12% 

Epoch 12
-------------------------------
Training loss: 1.121248  [16/3680]
Training loss: 1.080023  [1616/3680]
Training loss: 1.184661  [3216/3680]
Training accuracy: 81.44 %
Validation loss: 0.932883
Validation accuracy: 84.72% 

Epoch 13
-------------------------------
Training loss: 0.930486  [16/3680]
Training loss: 1.115030  [1616/3680]
Training loss: 1.173880  [3216/3680]
Training accuracy: 82.26 %
Validation loss: 0.884223
Validation accuracy: 84.72% 

Epoch 14
-------------------------------
Training loss: 0.822108  [16/3680]
Training loss: 1.277780  [1616/3680]
Training loss: 0.921104  [3216/3680]
Training accuracy: 83.04 %
Validation loss: 0.828170
Validation accuracy: 85.10% 

Epoch 15
-------------------------------
Training loss: 1.048347  [16/3680]
Training loss: 1.216079  [1616/3680]
Training loss: 0.906546  [3216/3680]
Training accuracy: 83.12 %
Validation loss: 0.793024
Validation accuracy: 85.59% 

Epoch 16
-------------------------------
Training loss: 1.204400  [16/3680]
Training loss: 1.062512  [1616/3680]
Training loss: 0.835529  [3216/3680]
Training accuracy: 83.83 %
Validation loss: 0.771220
Validation accuracy: 86.08% 

Epoch 17
-------------------------------
Training loss: 0.934439  [16/3680]
Training loss: 1.118514  [1616/3680]
Training loss: 0.839424  [3216/3680]
Training accuracy: 84.05 %
Validation loss: 0.746426
Validation accuracy: 86.19% 

Epoch 18
-------------------------------
Training loss: 1.188604  [16/3680]
Training loss: 1.087149  [1616/3680]
Training loss: 0.837536  [3216/3680]
Training accuracy: 84.08 %
Validation loss: 0.708745
Validation accuracy: 86.30% 

Epoch 19
-------------------------------
Training loss: 0.945341  [16/3680]
Training loss: 0.867007  [1616/3680]
Training loss: 0.792301  [3216/3680]
Training accuracy: 85.14 %
Validation loss: 0.678041
Validation accuracy: 86.57% 

Epoch 20
-------------------------------
Training loss: 1.087317  [16/3680]
Training loss: 0.738776  [1616/3680]
Training loss: 0.996497  [3216/3680]
Training accuracy: 84.40 %
Validation loss: 0.689224
Validation accuracy: 86.14% 

Epoch 21
-------------------------------
Training loss: 0.569454  [16/3680]
Training loss: 0.514318  [1616/3680]
Training loss: 0.909245  [3216/3680]
Training accuracy: 84.78 %
Validation loss: 0.647603
Validation accuracy: 86.63% 

Epoch 22
-------------------------------
Training loss: 0.744935  [16/3680]
Training loss: 0.842250  [1616/3680]
Training loss: 0.724406  [3216/3680]
Training accuracy: 84.38 %
Validation loss: 0.640544
Validation accuracy: 86.95% 

Epoch 23
-------------------------------
Training loss: 0.617126  [16/3680]
Training loss: 0.981002  [1616/3680]
Training loss: 0.856898  [3216/3680]
Training accuracy: 85.73 %
Validation loss: 0.625214
Validation accuracy: 86.90% 

Epoch 24
-------------------------------
Training loss: 0.908267  [16/3680]
Training loss: 0.812197  [1616/3680]
Training loss: 0.897753  [3216/3680]
Training accuracy: 85.41 %
Validation loss: 0.604175
Validation accuracy: 86.79% 

Epoch 25
-------------------------------
Training loss: 0.559767  [16/3680]
Training loss: 0.508763  [1616/3680]
Training loss: 0.746243  [3216/3680]
Training accuracy: 84.81 %
Validation loss: 0.585772
Validation accuracy: 87.34% 

Epoch 26
-------------------------------
Training loss: 0.696254  [16/3680]
Training loss: 0.748761  [1616/3680]
Training loss: 0.508543  [3216/3680]
Training accuracy: 85.60 %
Validation loss: 0.572173
Validation accuracy: 87.12% 

Epoch 27
-------------------------------
Training loss: 0.761554  [16/3680]
Training loss: 0.989896  [1616/3680]
Training loss: 1.063949  [3216/3680]
Training accuracy: 86.01 %
Validation loss: 0.571435
Validation accuracy: 87.28% 

Epoch 28
-------------------------------
Training loss: 0.908523  [16/3680]
Training loss: 0.356259  [1616/3680]
Training loss: 0.720626  [3216/3680]
Training accuracy: 86.49 %
Validation loss: 0.565777
Validation accuracy: 87.34% 

Epoch 29
-------------------------------
Training loss: 0.783543  [16/3680]
Training loss: 0.704634  [1616/3680]
Training loss: 0.543835  [3216/3680]
Training accuracy: 86.41 %
Validation loss: 0.542942
Validation accuracy: 87.55% 

Epoch 30
-------------------------------
Training loss: 0.551727  [16/3680]
Training loss: 0.661900  [1616/3680]
Training loss: 0.515981  [3216/3680]
Training accuracy: 86.17 %
Validation loss: 0.542895
Validation accuracy: 87.72% 

Epoch 31
-------------------------------
Training loss: 0.683310  [16/3680]
Training loss: 0.764459  [1616/3680]
Training loss: 0.461366  [3216/3680]
Training accuracy: 85.73 %
Validation loss: 0.540674
Validation accuracy: 87.17% 

Epoch 32
-------------------------------
Training loss: 0.792495  [16/3680]
Training loss: 0.529326  [1616/3680]
Training loss: 1.133872  [3216/3680]
Training accuracy: 86.01 %
Validation loss: 0.527912
Validation accuracy: 87.28% 

Epoch 33
-------------------------------
Training loss: 1.017782  [16/3680]
Training loss: 0.545638  [1616/3680]
Training loss: 0.730650  [3216/3680]
Training accuracy: 86.79 %
Validation loss: 0.517912
Validation accuracy: 87.61% 

Epoch 34
-------------------------------
Training loss: 0.656114  [16/3680]
Training loss: 0.716051  [1616/3680]
Training loss: 0.572505  [3216/3680]
Training accuracy: 86.52 %
Validation loss: 0.511104
Validation accuracy: 87.83% 

Epoch 35
-------------------------------
Training loss: 0.430951  [16/3680]
Training loss: 0.881022  [1616/3680]
Training loss: 0.721446  [3216/3680]
Training accuracy: 87.20 %
Validation loss: 0.513261
Validation accuracy: 87.66% 

Epoch 36
-------------------------------
Training loss: 0.422803  [16/3680]
Training loss: 0.722495  [1616/3680]
Training loss: 0.721955  [3216/3680]
Training accuracy: 86.98 %
Validation loss: 0.501063
Validation accuracy: 87.88% 

Epoch 37
-------------------------------
Training loss: 0.873330  [16/3680]
Training loss: 0.337484  [1616/3680]
Training loss: 0.623239  [3216/3680]
Training accuracy: 86.52 %
Validation loss: 0.512373
Validation accuracy: 87.39% 

Epoch 38
-------------------------------
Training loss: 0.573707  [16/3680]
Training loss: 1.055641  [1616/3680]
Training loss: 0.511531  [3216/3680]
Training accuracy: 87.17 %
Validation loss: 0.489674
Validation accuracy: 87.99% 

Epoch 39
-------------------------------
Training loss: 0.749169  [16/3680]
Training loss: 0.550005  [1616/3680]
Training loss: 0.598732  [3216/3680]
Training accuracy: 87.34 %
Validation loss: 0.497732
Validation accuracy: 88.37% 

Epoch 40
-------------------------------
Training loss: 0.675728  [16/3680]
Training loss: 0.496137  [1616/3680]
Training loss: 0.612587  [3216/3680]
Training accuracy: 86.71 %
Validation loss: 0.470655
Validation accuracy: 88.26% 

Epoch 41
-------------------------------
Training loss: 1.128058  [16/3680]
Training loss: 0.709657  [1616/3680]
Training loss: 0.824218  [3216/3680]
Training accuracy: 85.79 %
Validation loss: 0.480824
Validation accuracy: 88.48% 

Epoch 42
-------------------------------
Training loss: 0.901246  [16/3680]
Training loss: 0.487696  [1616/3680]
Training loss: 0.619659  [3216/3680]
Training accuracy: 87.26 %
Validation loss: 0.479356
Validation accuracy: 88.16% 

Epoch 43
-------------------------------
Training loss: 0.557608  [16/3680]
Training loss: 0.394230  [1616/3680]
Training loss: 0.622616  [3216/3680]
Training accuracy: 87.09 %
Validation loss: 0.473209
Validation accuracy: 87.83% 

Epoch 44
-------------------------------
Training loss: 0.379847  [16/3680]
Training loss: 0.445704  [1616/3680]
Training loss: 0.459600  [3216/3680]
Training accuracy: 87.85 %
Validation loss: 0.459900
Validation accuracy: 88.43% 

Epoch 45
-------------------------------
Training loss: 0.648042  [16/3680]
Training loss: 0.549604  [1616/3680]
Training loss: 0.471466  [3216/3680]
Training accuracy: 88.10 %
Validation loss: 0.456100
Validation accuracy: 88.32% 

Epoch 46
-------------------------------
Training loss: 0.339137  [16/3680]
Training loss: 0.248434  [1616/3680]
Training loss: 0.649079  [3216/3680]
Training accuracy: 87.96 %
Validation loss: 0.459444
Validation accuracy: 88.48% 

Early stopping
Done!

Elapsed time: 10331.195709943771 seconds

                         precision    recall  f1-score   support

             Abyssinian       0.77      0.76      0.76        49
       American Bulldog       0.80      0.88      0.84        50
  American pitbull terr       0.84      0.54      0.66        50
           Basset hound       0.94      0.96      0.95        50
                 Beagle       0.94      0.92      0.93        50
                 Bengal       0.77      0.86      0.81        50
                 Birman       0.76      0.84      0.80        50
                 Bombay       0.89      0.93      0.91        44
                  Boxer       0.80      0.90      0.85        50
      British Shorthair       0.84      0.72      0.77        50
              Chihuahua       0.94      0.88      0.91        50
           Egyptian Mau       0.93      0.86      0.89        49
 English cocker spaniel       0.92      0.94      0.93        50
         English setter       0.98      0.90      0.94        50
     German shorthaired       0.85      1.00      0.92        50
         Great pyrenees       0.92      0.96      0.94        50
               Havanese       0.84      0.96      0.90        50
          Japanese chin       0.98      0.98      0.98        50
               Keeshond       1.00      1.00      1.00        50
             Leonberger       0.98      1.00      0.99        50
             Maine Coon       0.76      0.78      0.77        50
     Miniature pinscher       0.92      0.90      0.91        50
           Newfoundland       0.98      0.98      0.98        50
                Persian       0.85      0.82      0.84        50
             Pomeranian       0.98      0.96      0.97        50
                    Pug       0.96      0.90      0.93        50
                Ragdoll       0.78      0.72      0.75        50
           Russian blue       0.80      0.80      0.80        50
          Saint bernard       0.96      0.98      0.97        50
                Samoyed       0.94      1.00      0.97        50
       Scottish terrier       0.92      0.96      0.94        50
              Shiba inu       0.94      0.96      0.95        50
                Siamese       0.96      0.86      0.91        50
                 Sphynx       0.84      0.92      0.88        50
Staffordshire bull terr       0.65      0.73      0.69        45
        Wheaten terrier       1.00      0.86      0.92        50
      Yorkshire terrier       0.96      0.90      0.93        50

               accuracy                           0.89      1837
              macro avg       0.89      0.89      0.89      1837
           weighted avg       0.89      0.89      0.89      1837

Test accuracy: 0.8873162765378334
