Downloading https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz to ../../../../../../work3/s226536/datasets/oxford-iiit-pet/images.tar.gz
Extracting ../../../../../../work3/s226536/datasets/oxford-iiit-pet/images.tar.gz to ../../../../../../work3/s226536/datasets/oxford-iiit-pet
Downloading https://thor.robots.ox.ac.uk/datasets/pets/annotations.tar.gz to ../../../../../../work3/s226536/datasets/oxford-iiit-pet/annotations.tar.gz
Extracting ../../../../../../work3/s226536/datasets/oxford-iiit-pet/annotations.tar.gz to ../../../../../../work3/s226536/datasets/oxford-iiit-pet
-------------------------------------
Generating 5 images for breed Abyssinian...

Not using data augmentation
Using cuda device
Epoch 1
-------------------------------
Training loss: 4.012317  [16/3680]
Training loss: 3.578109  [1616/3680]
Training loss: 3.246540  [3216/3680]
Training accuracy: 19.76 %
Validation loss: 3.123463
Validation accuracy: 21.89% 

Epoch 2
-------------------------------
Training loss: 3.223058  [16/3680]
Training loss: 3.096237  [1616/3680]
Training loss: 2.799976  [3216/3680]
Training accuracy: 44.86 %
Validation loss: 2.632670
Validation accuracy: 46.02% 

Epoch 3
-------------------------------
Training loss: 2.680188  [16/3680]
Training loss: 2.475725  [1616/3680]
Training loss: 2.229170  [3216/3680]
Training accuracy: 61.11 %
Validation loss: 2.225147
Validation accuracy: 61.24% 

Epoch 4
-------------------------------
Training loss: 2.453800  [16/3680]
Training loss: 2.491781  [1616/3680]
Training loss: 2.114019  [3216/3680]
Training accuracy: 69.18 %
Validation loss: 1.897689
Validation accuracy: 69.54% 

Epoch 5
-------------------------------
Training loss: 2.185821  [16/3680]
Training loss: 1.887863  [1616/3680]
Training loss: 1.693813  [3216/3680]
Training accuracy: 74.78 %
Validation loss: 1.635700
Validation accuracy: 76.26% 

Epoch 6
-------------------------------
Training loss: 1.930776  [16/3680]
Training loss: 1.658632  [1616/3680]
Training loss: 1.526367  [3216/3680]
Training accuracy: 79.16 %
Validation loss: 1.445966
Validation accuracy: 79.53% 

Epoch 7
-------------------------------
Training loss: 1.345086  [16/3680]
Training loss: 1.734736  [1616/3680]
Training loss: 1.444444  [3216/3680]
Training accuracy: 81.96 %
Validation loss: 1.300148
Validation accuracy: 81.22% 

Epoch 8
-------------------------------
Training loss: 1.629925  [16/3680]
Training loss: 1.344332  [1616/3680]
Training loss: 1.392872  [3216/3680]
Training accuracy: 83.15 %
Validation loss: 1.134801
Validation accuracy: 83.13% 

Epoch 9
-------------------------------
Training loss: 1.423552  [16/3680]
Training loss: 0.968041  [1616/3680]
Training loss: 1.304438  [3216/3680]
Training accuracy: 84.67 %
Validation loss: 1.048410
Validation accuracy: 84.44% 

Epoch 10
-------------------------------
Training loss: 1.317935  [16/3680]
Training loss: 0.839507  [1616/3680]
Training loss: 1.249156  [3216/3680]
Training accuracy: 84.76 %
Validation loss: 0.971955
Validation accuracy: 84.17% 

Epoch 11
-------------------------------
Training loss: 1.065259  [16/3680]
Training loss: 0.957424  [1616/3680]
Training loss: 1.128843  [3216/3680]
Training accuracy: 85.62 %
Validation loss: 0.917383
Validation accuracy: 85.26% 

Epoch 12
-------------------------------
Training loss: 1.105135  [16/3680]
Training loss: 0.800157  [1616/3680]
Training loss: 1.248300  [3216/3680]
Training accuracy: 86.14 %
Validation loss: 0.843643
Validation accuracy: 85.75% 

Epoch 13
-------------------------------
Training loss: 0.977600  [16/3680]
Training loss: 0.927325  [1616/3680]
Training loss: 0.890345  [3216/3680]
Training accuracy: 86.55 %
Validation loss: 0.809862
Validation accuracy: 85.70% 

Epoch 14
-------------------------------
Training loss: 1.069233  [16/3680]
Training loss: 0.609977  [1616/3680]
Training loss: 0.661448  [3216/3680]
Training accuracy: 86.68 %
Validation loss: 0.776120
Validation accuracy: 86.57% 

Epoch 15
-------------------------------
Training loss: 0.548345  [16/3680]
Training loss: 0.892983  [1616/3680]
Training loss: 0.883689  [3216/3680]
Training accuracy: 87.20 %
Validation loss: 0.732059
Validation accuracy: 86.74% 

Epoch 16
-------------------------------
Training loss: 0.842564  [16/3680]
Training loss: 0.673202  [1616/3680]
Training loss: 0.830310  [3216/3680]
Training accuracy: 88.07 %
Validation loss: 0.723847
Validation accuracy: 86.30% 

Epoch 17
-------------------------------
Training loss: 0.869666  [16/3680]
Training loss: 0.739506  [1616/3680]
Training loss: 0.694274  [3216/3680]
Training accuracy: 88.80 %
Validation loss: 0.680366
Validation accuracy: 86.68% 

Epoch 18
-------------------------------
Training loss: 0.736475  [16/3680]
Training loss: 0.896468  [1616/3680]
Training loss: 0.824499  [3216/3680]
Training accuracy: 88.26 %
Validation loss: 0.654874
Validation accuracy: 87.83% 

Epoch 19
-------------------------------
Training loss: 0.955560  [16/3680]
Training loss: 0.547369  [1616/3680]
Training loss: 0.564089  [3216/3680]
Training accuracy: 88.89 %
Validation loss: 0.646922
Validation accuracy: 87.01% 

Epoch 20
-------------------------------
Training loss: 0.693440  [16/3680]
Training loss: 0.493356  [1616/3680]
Training loss: 0.596791  [3216/3680]
Training accuracy: 88.99 %
Validation loss: 0.632732
Validation accuracy: 87.61% 

Epoch 21
-------------------------------
Training loss: 0.601227  [16/3680]
Training loss: 0.717929  [1616/3680]
Training loss: 1.149320  [3216/3680]
Training accuracy: 89.32 %
Validation loss: 0.599986
Validation accuracy: 87.55% 

Epoch 22
-------------------------------
Training loss: 0.528203  [16/3680]
Training loss: 0.427429  [1616/3680]
Training loss: 0.603149  [3216/3680]
Training accuracy: 90.03 %
Validation loss: 0.588712
Validation accuracy: 87.66% 

Epoch 23
-------------------------------
Training loss: 0.867672  [16/3680]
Training loss: 0.640636  [1616/3680]
Training loss: 0.410097  [3216/3680]
Training accuracy: 89.48 %
Validation loss: 0.587353
Validation accuracy: 87.50% 

Early stopping
Done!

Elapsed time: 1447.1795485019684 seconds

Current time: 18:03:36
                         precision    recall  f1-score   support

             Abyssinian       0.78      0.78      0.78        49
       American Bulldog       0.75      0.94      0.83        50
  American pitbull terr       0.70      0.46      0.55        50
           Basset hound       0.92      0.92      0.92        50
                 Beagle       0.87      0.90      0.88        50
                 Bengal       0.74      0.86      0.80        50
                 Birman       0.74      0.80      0.77        50
                 Bombay       0.84      0.93      0.88        44
                  Boxer       0.82      0.82      0.82        50
      British Shorthair       0.88      0.74      0.80        50
              Chihuahua       0.93      0.84      0.88        50
           Egyptian Mau       0.91      0.80      0.85        49
 English cocker spaniel       0.87      0.92      0.89        50
         English setter       0.96      0.86      0.91        50
     German shorthaired       0.88      1.00      0.93        50
         Great pyrenees       0.90      0.94      0.92        50
               Havanese       0.84      0.94      0.89        50
          Japanese chin       0.96      0.94      0.95        50
               Keeshond       0.98      1.00      0.99        50
             Leonberger       0.98      0.98      0.98        50
             Maine Coon       0.77      0.68      0.72        50
     Miniature pinscher       0.93      0.82      0.87        50
           Newfoundland       1.00      0.98      0.99        50
                Persian       0.78      0.84      0.81        50
             Pomeranian       0.96      0.90      0.93        50
                    Pug       0.96      0.92      0.94        50
                Ragdoll       0.80      0.74      0.77        50
           Russian blue       0.78      0.70      0.74        50
          Saint bernard       0.91      0.98      0.94        50
                Samoyed       0.88      1.00      0.93        50
       Scottish terrier       0.93      1.00      0.96        50
              Shiba inu       0.92      0.98      0.95        50
                Siamese       0.91      0.84      0.87        50
                 Sphynx       0.84      0.92      0.88        50
Staffordshire bull terr       0.62      0.64      0.63        45
        Wheaten terrier       0.91      0.86      0.89        50
      Yorkshire terrier       0.98      0.90      0.94        50

               accuracy                           0.87      1837
              macro avg       0.87      0.87      0.86      1837
           weighted avg       0.87      0.87      0.87      1837

Test accuracy: 0.8671747414262384
The metadata of the previous execution is...
{'training_images_percentage': 1, 'epochs': 55, 'learning_rate': 0.001, 'batch_size': 16, 'data_augmentation': 'no', 'subject_driven_technique': 'dreambooth', 'number_of_samples': 5, 'images_to_generate': 5, 'FID_threshold': 100, 'check_quality': False, 'path_to_dataset': '../../../../../../work3/s226536/datasets/oxford-iiit-pet', 'DATA_DIR': '../../../../../../work3/s226536/datasets'}

Preparing next execution...
Finished preparing next execution...
