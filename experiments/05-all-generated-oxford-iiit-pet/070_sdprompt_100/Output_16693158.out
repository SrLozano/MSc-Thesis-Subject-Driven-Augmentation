Not using data augmentation
Using cuda device
Epoch 1
-------------------------------
Training loss: 4.023079  [16/3571]
Training loss: 3.517304  [1616/3571]
Training loss: 3.261263  [3216/3571]
Training accuracy: 35.73 %
Validation loss: 3.205133
Validation accuracy: 19.16% 

Epoch 2
-------------------------------
Training loss: 2.708492  [16/3571]
Training loss: 2.621038  [1616/3571]
Training loss: 2.259859  [3216/3571]
Training accuracy: 68.08 %
Validation loss: 2.710571
Validation accuracy: 40.28% 

Epoch 3
-------------------------------
Training loss: 2.215549  [16/3571]
Training loss: 1.953407  [1616/3571]
Training loss: 1.874014  [3216/3571]
Training accuracy: 80.87 %
Validation loss: 2.323920
Validation accuracy: 51.58% 

Epoch 4
-------------------------------
Training loss: 1.664219  [16/3571]
Training loss: 1.840387  [1616/3571]
Training loss: 1.557816  [3216/3571]
Training accuracy: 86.03 %
Validation loss: 2.067954
Validation accuracy: 57.21% 

Epoch 5
-------------------------------
Training loss: 1.677934  [16/3571]
Training loss: 1.684969  [1616/3571]
Training loss: 1.681352  [3216/3571]
Training accuracy: 88.35 %
Validation loss: 1.846984
Validation accuracy: 61.24% 

Epoch 6
-------------------------------
Training loss: 1.372837  [16/3571]
Training loss: 1.308933  [1616/3571]
Training loss: 0.817404  [3216/3571]
Training accuracy: 89.78 %
Validation loss: 1.706131
Validation accuracy: 63.54% 

Epoch 7
-------------------------------
Training loss: 0.772754  [16/3571]
Training loss: 0.987172  [1616/3571]
Training loss: 1.277377  [3216/3571]
Training accuracy: 91.60 %
Validation loss: 1.591060
Validation accuracy: 65.56% 

Epoch 8
-------------------------------
Training loss: 0.988994  [16/3571]
Training loss: 0.751981  [1616/3571]
Training loss: 0.910717  [3216/3571]
Training accuracy: 91.77 %
Validation loss: 1.480454
Validation accuracy: 66.59% 

Epoch 9
-------------------------------
Training loss: 1.176611  [16/3571]
Training loss: 0.662378  [1616/3571]
Training loss: 0.852266  [3216/3571]
Training accuracy: 92.78 %
Validation loss: 1.434968
Validation accuracy: 65.61% 

Epoch 10
-------------------------------
Training loss: 0.827570  [16/3571]
Training loss: 0.771503  [1616/3571]
Training loss: 0.752186  [3216/3571]
Training accuracy: 93.06 %
Validation loss: 1.372544
Validation accuracy: 67.03% 

Epoch 11
-------------------------------
Training loss: 0.423517  [16/3571]
Training loss: 0.695695  [1616/3571]
Training loss: 0.586378  [3216/3571]
Training accuracy: 93.45 %
Validation loss: 1.296735
Validation accuracy: 68.40% 

Epoch 12
-------------------------------
Training loss: 0.622694  [16/3571]
Training loss: 0.605352  [1616/3571]
Training loss: 0.717113  [3216/3571]
Training accuracy: 93.64 %
Validation loss: 1.274158
Validation accuracy: 68.29% 

Epoch 13
-------------------------------
Training loss: 0.502997  [16/3571]
Training loss: 0.520059  [1616/3571]
Training loss: 0.637507  [3216/3571]
Training accuracy: 93.59 %
Validation loss: 1.317609
Validation accuracy: 65.50% 

Epoch 14
-------------------------------
Training loss: 0.381744  [16/3571]
Training loss: 0.334767  [1616/3571]
Training loss: 0.355543  [3216/3571]
Training accuracy: 94.12 %
Validation loss: 1.249783
Validation accuracy: 66.32% 

Epoch 15
-------------------------------
Training loss: 0.482730  [16/3571]
Training loss: 0.460578  [1616/3571]
Training loss: 0.462594  [3216/3571]
Training accuracy: 94.54 %
Validation loss: 1.249675
Validation accuracy: 66.05% 

Epoch 16
-------------------------------
Training loss: 0.381950  [16/3571]
Training loss: 0.350756  [1616/3571]
Training loss: 0.381597  [3216/3571]
Training accuracy: 94.82 %
Validation loss: 1.174800
Validation accuracy: 68.45% 

Epoch 17
-------------------------------
Training loss: 0.433863  [16/3571]
Training loss: 0.498960  [1616/3571]
Training loss: 0.409701  [3216/3571]
Training accuracy: 94.60 %
Validation loss: 1.163708
Validation accuracy: 67.58% 

Epoch 18
-------------------------------
Training loss: 0.739043  [16/3571]
Training loss: 0.328802  [1616/3571]
Training loss: 0.525273  [3216/3571]
Training accuracy: 95.41 %
Validation loss: 1.162614
Validation accuracy: 66.65% 

Epoch 19
-------------------------------
Training loss: 0.273085  [16/3571]
Training loss: 0.221310  [1616/3571]
Training loss: 0.402008  [3216/3571]
Training accuracy: 95.24 %
Validation loss: 1.153211
Validation accuracy: 66.54% 

Epoch 20
-------------------------------
Training loss: 0.202811  [16/3571]
Training loss: 0.261644  [1616/3571]
Training loss: 0.354835  [3216/3571]
Training accuracy: 95.24 %
Validation loss: 1.177204
Validation accuracy: 65.72% 

Epoch 21
-------------------------------
Training loss: 0.557818  [16/3571]
Training loss: 0.399676  [1616/3571]
Training loss: 0.267233  [3216/3571]
Training accuracy: 95.88 %
Validation loss: 1.189402
Validation accuracy: 65.01% 

Early stopping
Done!

Elapsed time: 2074.833724975586 seconds

Current time: 15:02:18
                         precision    recall  f1-score   support

             Abyssinian       0.41      0.27      0.32        49
       American Bulldog       0.59      0.58      0.59        50
  American pitbull terr       0.52      0.70      0.60        50
           Basset hound       0.79      0.84      0.82        50
                 Beagle       0.97      0.66      0.79        50
                 Bengal       0.50      0.06      0.11        50
                 Birman       0.30      0.38      0.34        50
                 Bombay       0.24      0.93      0.39        44
                  Boxer       0.88      0.42      0.57        50
      British Shorthair       0.83      0.30      0.44        50
              Chihuahua       0.88      0.76      0.82        50
           Egyptian Mau       0.40      0.96      0.56        49
 English cocker spaniel       0.72      0.52      0.60        50
         English setter       0.83      0.86      0.84        50
     German shorthaired       0.63      1.00      0.78        50
         Great pyrenees       0.74      1.00      0.85        50
               Havanese       0.94      0.34      0.50        50
          Japanese chin       1.00      0.76      0.86        50
               Keeshond       0.94      0.94      0.94        50
             Leonberger       0.80      0.86      0.83        50
             Maine Coon       0.72      0.26      0.38        50
     Miniature pinscher       0.95      0.80      0.87        50
           Newfoundland       0.80      0.96      0.87        50
                Persian       0.62      0.68      0.65        50
             Pomeranian       1.00      0.74      0.85        50
                    Pug       1.00      0.90      0.95        50
                Ragdoll       0.07      0.02      0.03        50
           Russian blue       0.27      0.30      0.28        50
          Saint bernard       0.98      0.86      0.91        50
                Samoyed       0.83      0.96      0.89        50
       Scottish terrier       0.85      0.82      0.84        50
              Shiba inu       0.92      0.94      0.93        50
                Siamese       0.54      0.58      0.56        50
                 Sphynx       0.00      0.00      0.00        50
Staffordshire bull terr       0.57      0.69      0.63        45
        Wheaten terrier       0.48      0.94      0.64        50
      Yorkshire terrier       1.00      0.68      0.81        50

               accuracy                           0.65      1837
              macro avg       0.69      0.66      0.64      1837
           weighted avg       0.69      0.65      0.64      1837

Test accuracy: 0.6548720740337507
The metadata of the previous execution is...
{'training_images_percentage': 0.05, 'epochs': 55, 'learning_rate': 0.001, 'batch_size': 16, 'data_augmentation': 'no', 'subject_driven_technique': 'stable-diffusion-prompt', 'number_of_samples': 5, 'images_to_generate': 100, 'FID_threshold': 100, 'check_quality': False, 'path_to_dataset': '../../../../../../work3/s226536/datasets/oxford-iiit-pet', 'DATA_DIR': '../../../../../../work3/s226536/datasets'}

Preparing next execution...
Finished preparing next execution...
