Not using data augmentation
Using cuda device
Epoch 1
-------------------------------
Training loss: 3.907668  [16/7170]
Training loss: 3.274370  [1616/7170]
Training loss: 3.180343  [3216/7170]
Training loss: 2.642926  [4816/7170]
Training loss: 2.369736  [6416/7170]
Training accuracy: 67.13 %
Validation loss: 2.642003
Validation accuracy: 43.45% 

Epoch 2
-------------------------------
Training loss: 2.261158  [16/7170]
Training loss: 2.389265  [1616/7170]
Training loss: 2.007124  [3216/7170]
Training loss: 1.633502  [4816/7170]
Training loss: 1.785375  [6416/7170]
Training accuracy: 84.35 %
Validation loss: 2.032002
Validation accuracy: 57.21% 

Epoch 3
-------------------------------
Training loss: 1.693832  [16/7170]
Training loss: 1.316052  [1616/7170]
Training loss: 1.276728  [3216/7170]
Training loss: 1.027956  [4816/7170]
Training loss: 0.914480  [6416/7170]
Training accuracy: 88.97 %
Validation loss: 1.674423
Validation accuracy: 62.50% 

Epoch 4
-------------------------------
Training loss: 1.442658  [16/7170]
Training loss: 1.057100  [1616/7170]
Training loss: 0.862193  [3216/7170]
Training loss: 0.784704  [4816/7170]
Training loss: 0.845751  [6416/7170]
Training accuracy: 91.72 %
Validation loss: 1.479466
Validation accuracy: 65.28% 

Epoch 5
-------------------------------
Training loss: 0.781548  [16/7170]
Training loss: 0.556642  [1616/7170]
Training loss: 0.497704  [3216/7170]
Training loss: 0.641762  [4816/7170]
Training loss: 0.713081  [6416/7170]
Training accuracy: 92.06 %
Validation loss: 1.368556
Validation accuracy: 65.99% 

Epoch 6
-------------------------------
Training loss: 0.552419  [16/7170]
Training loss: 0.451682  [1616/7170]
Training loss: 0.693007  [3216/7170]
Training loss: 0.400674  [4816/7170]
Training loss: 0.549974  [6416/7170]
Training accuracy: 93.63 %
Validation loss: 1.278849
Validation accuracy: 66.43% 

Epoch 7
-------------------------------
Training loss: 0.413863  [16/7170]
Training loss: 0.412070  [1616/7170]
Training loss: 0.348846  [3216/7170]
Training loss: 0.554773  [4816/7170]
Training loss: 0.643910  [6416/7170]
Training accuracy: 93.75 %
Validation loss: 1.215260
Validation accuracy: 67.03% 

Epoch 8
-------------------------------
Training loss: 0.629036  [16/7170]
Training loss: 0.491366  [1616/7170]
Training loss: 0.608349  [3216/7170]
Training loss: 0.372737  [4816/7170]
Training loss: 0.411138  [6416/7170]
Training accuracy: 94.23 %
Validation loss: 1.214224
Validation accuracy: 65.88% 

Epoch 9
-------------------------------
Training loss: 0.361656  [16/7170]
Training loss: 0.350562  [1616/7170]
Training loss: 0.677043  [3216/7170]
Training loss: 0.463568  [4816/7170]
Training loss: 0.368874  [6416/7170]
Training accuracy: 94.71 %
Validation loss: 1.132292
Validation accuracy: 67.74% 

Epoch 10
-------------------------------
Training loss: 0.572117  [16/7170]
Training loss: 0.338593  [1616/7170]
Training loss: 0.505855  [3216/7170]
Training loss: 0.337175  [4816/7170]
Training loss: 0.273130  [6416/7170]
Training accuracy: 94.90 %
Validation loss: 1.152070
Validation accuracy: 66.32% 

Epoch 11
-------------------------------
Training loss: 0.308682  [16/7170]
Training loss: 0.416052  [1616/7170]
Training loss: 0.466743  [3216/7170]
Training loss: 0.352220  [4816/7170]
Training loss: 0.309817  [6416/7170]
Training accuracy: 94.94 %
Validation loss: 1.101630
Validation accuracy: 67.96% 

Epoch 12
-------------------------------
Training loss: 0.230139  [16/7170]
Training loss: 0.313419  [1616/7170]
Training loss: 0.371607  [3216/7170]
Training loss: 0.313834  [4816/7170]
Training loss: 0.370892  [6416/7170]
Training accuracy: 95.24 %
Validation loss: 1.084342
Validation accuracy: 67.96% 

Epoch 13
-------------------------------
Training loss: 0.267237  [16/7170]
Training loss: 0.298612  [1616/7170]
Training loss: 0.331717  [3216/7170]
Training loss: 0.550414  [4816/7170]
Training loss: 0.289794  [6416/7170]
Training accuracy: 95.41 %
Validation loss: 1.116193
Validation accuracy: 66.70% 

Epoch 14
-------------------------------
Training loss: 0.372948  [16/7170]
Training loss: 0.338767  [1616/7170]
Training loss: 0.346936  [3216/7170]
Training loss: 0.365160  [4816/7170]
Training loss: 0.252400  [6416/7170]
Training accuracy: 95.48 %
Validation loss: 1.083358
Validation accuracy: 66.43% 

Epoch 15
-------------------------------
Training loss: 0.474512  [16/7170]
Training loss: 0.229591  [1616/7170]
Training loss: 0.256272  [3216/7170]
Training loss: 0.445929  [4816/7170]
Training loss: 0.152705  [6416/7170]
Training accuracy: 95.68 %
Validation loss: 1.010748
Validation accuracy: 69.16% 

Epoch 16
-------------------------------
Training loss: 0.293183  [16/7170]
Training loss: 0.184743  [1616/7170]
Training loss: 0.223015  [3216/7170]
Training loss: 0.157611  [4816/7170]
Training loss: 0.216843  [6416/7170]
Training accuracy: 95.69 %
Validation loss: 1.068202
Validation accuracy: 67.41% 

Epoch 17
-------------------------------
Training loss: 0.144770  [16/7170]
Training loss: 0.222056  [1616/7170]
Training loss: 0.118753  [3216/7170]
Training loss: 0.311417  [4816/7170]
Training loss: 0.205543  [6416/7170]
Training accuracy: 96.01 %
Validation loss: 1.018777
Validation accuracy: 68.78% 

Epoch 18
-------------------------------
Training loss: 0.178322  [16/7170]
Training loss: 0.236115  [1616/7170]
Training loss: 0.262705  [3216/7170]
Training loss: 0.213961  [4816/7170]
Training loss: 0.270683  [6416/7170]
Training accuracy: 96.09 %
Validation loss: 0.991715
Validation accuracy: 69.43% 

Epoch 19
-------------------------------
Training loss: 0.478298  [16/7170]
Training loss: 0.176448  [1616/7170]
Training loss: 0.344029  [3216/7170]
Training loss: 0.137130  [4816/7170]
Training loss: 0.260566  [6416/7170]
Training accuracy: 96.00 %
Validation loss: 0.998058
Validation accuracy: 68.56% 

Epoch 20
-------------------------------
Training loss: 0.338092  [16/7170]
Training loss: 0.187672  [1616/7170]
Training loss: 0.383686  [3216/7170]
Training loss: 0.430186  [4816/7170]
Training loss: 0.586640  [6416/7170]
Training accuracy: 96.14 %
Validation loss: 0.970424
Validation accuracy: 69.81% 

Epoch 21
-------------------------------
Training loss: 0.368768  [16/7170]
Training loss: 0.210410  [1616/7170]
Training loss: 0.237949  [3216/7170]
Training loss: 0.385757  [4816/7170]
Training loss: 0.276255  [6416/7170]
Training accuracy: 95.89 %
Validation loss: 0.969868
Validation accuracy: 68.61% 

Epoch 22
-------------------------------
Training loss: 0.086317  [16/7170]
Training loss: 0.351771  [1616/7170]
Training loss: 0.204753  [3216/7170]
Training loss: 0.125340  [4816/7170]
Training loss: 0.230595  [6416/7170]
Training accuracy: 96.67 %
Validation loss: 0.984387
Validation accuracy: 69.16% 

Epoch 23
-------------------------------
Training loss: 0.357177  [16/7170]
Training loss: 0.196209  [1616/7170]
Training loss: 0.146348  [3216/7170]
Training loss: 0.309193  [4816/7170]
Training loss: 0.295829  [6416/7170]
Training accuracy: 96.33 %
Validation loss: 0.981650
Validation accuracy: 68.94% 

Epoch 24
-------------------------------
Training loss: 0.148006  [16/7170]
Training loss: 0.119324  [1616/7170]
Training loss: 0.154233  [3216/7170]
Training loss: 0.324849  [4816/7170]
Training loss: 0.177185  [6416/7170]
Training accuracy: 96.37 %
Validation loss: 1.046265
Validation accuracy: 67.19% 

Epoch 25
-------------------------------
Training loss: 0.151848  [16/7170]
Training loss: 0.102364  [1616/7170]
Training loss: 0.212536  [3216/7170]
Training loss: 0.280931  [4816/7170]
Training loss: 0.240924  [6416/7170]
Training accuracy: 96.33 %
Validation loss: 0.987098
Validation accuracy: 68.56% 

Early stopping
Done!

Elapsed time: 4693.697896242142 seconds

Current time: 11:52:42
                         precision    recall  f1-score   support

             Abyssinian       0.74      0.41      0.53        49
       American Bulldog       0.61      0.50      0.55        50
  American pitbull terr       0.39      0.84      0.53        50
           Basset hound       0.82      0.94      0.88        50
                 Beagle       0.93      0.80      0.86        50
                 Bengal       0.43      0.06      0.11        50
                 Birman       0.36      0.32      0.34        50
                 Bombay       0.32      0.93      0.48        44
                  Boxer       0.87      0.52      0.65        50
      British Shorthair       0.81      0.58      0.67        50
              Chihuahua       0.95      0.72      0.82        50
           Egyptian Mau       0.38      1.00      0.55        49
 English cocker spaniel       0.87      0.68      0.76        50
         English setter       0.82      0.80      0.81        50
     German shorthaired       0.78      0.98      0.87        50
         Great pyrenees       0.70      0.98      0.82        50
               Havanese       0.97      0.56      0.71        50
          Japanese chin       1.00      0.86      0.92        50
               Keeshond       0.96      1.00      0.98        50
             Leonberger       0.76      0.88      0.81        50
             Maine Coon       0.85      0.34      0.49        50
     Miniature pinscher       0.95      0.72      0.82        50
           Newfoundland       0.80      0.96      0.87        50
                Persian       0.60      0.50      0.54        50
             Pomeranian       1.00      0.66      0.80        50
                    Pug       1.00      0.86      0.92        50
                Ragdoll       0.16      0.16      0.16        50
           Russian blue       0.53      0.46      0.49        50
          Saint bernard       0.98      0.86      0.91        50
                Samoyed       0.79      0.96      0.86        50
       Scottish terrier       0.95      0.84      0.89        50
              Shiba inu       0.88      0.98      0.92        50
                Siamese       0.57      0.60      0.58        50
                 Sphynx       0.92      0.22      0.35        50
Staffordshire bull terr       0.71      0.44      0.55        45
        Wheaten terrier       0.56      0.98      0.71        50
      Yorkshire terrier       1.00      0.66      0.80        50

               accuracy                           0.69      1837
              macro avg       0.75      0.69      0.68      1837
           weighted avg       0.75      0.69      0.69      1837

Test accuracy: 0.6908002177463255
The metadata of the previous execution is...
{'training_images_percentage': 0.05, 'epochs': 55, 'learning_rate': 0.001, 'batch_size': 16, 'data_augmentation': 'no', 'subject_driven_technique': 'stable-diffusion-prompt', 'number_of_samples': 5, 'images_to_generate': 200, 'FID_threshold': 100, 'check_quality': False, 'path_to_dataset': '../../../../../../work3/s226536/datasets/oxford-iiit-pet', 'DATA_DIR': '../../../../../../work3/s226536/datasets'}

Preparing next execution...
Finished preparing next execution...
