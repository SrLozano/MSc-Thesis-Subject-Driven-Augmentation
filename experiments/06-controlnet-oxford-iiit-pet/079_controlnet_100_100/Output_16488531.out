Not using data augmentation
Using cuda device
Epoch 1
-------------------------------
Training loss: 4.179427  [16/3680]
Training loss: 3.401533  [1616/3680]
Training loss: 3.192011  [3216/3680]
Training accuracy: 23.51 %
Validation loss: 3.130775
Validation accuracy: 23.69% 

Epoch 2
-------------------------------
Training loss: 3.052250  [16/3680]
Training loss: 3.056526  [1616/3680]
Training loss: 2.803066  [3216/3680]
Training accuracy: 47.28 %
Validation loss: 2.625934
Validation accuracy: 50.00% 

Epoch 3
-------------------------------
Training loss: 2.875107  [16/3680]
Training loss: 2.736958  [1616/3680]
Training loss: 2.347831  [3216/3680]
Training accuracy: 61.79 %
Validation loss: 2.240321
Validation accuracy: 64.79% 

Epoch 4
-------------------------------
Training loss: 2.337316  [16/3680]
Training loss: 2.075161  [1616/3680]
Training loss: 2.241275  [3216/3680]
Training accuracy: 69.18 %
Validation loss: 1.911045
Validation accuracy: 72.98% 

Epoch 5
-------------------------------
Training loss: 1.887254  [16/3680]
Training loss: 1.846768  [1616/3680]
Training loss: 1.730150  [3216/3680]
Training accuracy: 74.97 %
Validation loss: 1.634267
Validation accuracy: 77.57% 

Epoch 6
-------------------------------
Training loss: 1.746957  [16/3680]
Training loss: 1.520983  [1616/3680]
Training loss: 1.517920  [3216/3680]
Training accuracy: 77.01 %
Validation loss: 1.456099
Validation accuracy: 80.19% 

Epoch 7
-------------------------------
Training loss: 1.549059  [16/3680]
Training loss: 1.610094  [1616/3680]
Training loss: 1.157972  [3216/3680]
Training accuracy: 80.84 %
Validation loss: 1.281105
Validation accuracy: 81.77% 

Epoch 8
-------------------------------
Training loss: 1.312664  [16/3680]
Training loss: 1.570127  [1616/3680]
Training loss: 1.599210  [3216/3680]
Training accuracy: 81.60 %
Validation loss: 1.171899
Validation accuracy: 83.13% 

Epoch 9
-------------------------------
Training loss: 1.073231  [16/3680]
Training loss: 1.084851  [1616/3680]
Training loss: 1.055076  [3216/3680]
Training accuracy: 82.39 %
Validation loss: 1.073399
Validation accuracy: 84.17% 

Epoch 10
-------------------------------
Training loss: 1.199503  [16/3680]
Training loss: 1.004689  [1616/3680]
Training loss: 1.204017  [3216/3680]
Training accuracy: 83.64 %
Validation loss: 0.973879
Validation accuracy: 85.26% 

Epoch 11
-------------------------------
Training loss: 1.090405  [16/3680]
Training loss: 0.984551  [1616/3680]
Training loss: 0.797402  [3216/3680]
Training accuracy: 85.16 %
Validation loss: 0.930541
Validation accuracy: 85.81% 

Epoch 12
-------------------------------
Training loss: 1.147915  [16/3680]
Training loss: 1.219625  [1616/3680]
Training loss: 1.208462  [3216/3680]
Training accuracy: 85.68 %
Validation loss: 0.861540
Validation accuracy: 85.53% 

Epoch 13
-------------------------------
Training loss: 0.763705  [16/3680]
Training loss: 0.693105  [1616/3680]
Training loss: 0.929715  [3216/3680]
Training accuracy: 85.98 %
Validation loss: 0.808548
Validation accuracy: 86.74% 

Epoch 14
-------------------------------
Training loss: 0.723454  [16/3680]
Training loss: 0.566084  [1616/3680]
Training loss: 0.810819  [3216/3680]
Training accuracy: 86.49 %
Validation loss: 0.777257
Validation accuracy: 87.01% 

Epoch 15
-------------------------------
Training loss: 1.031550  [16/3680]
Training loss: 1.031703  [1616/3680]
Training loss: 0.841290  [3216/3680]
Training accuracy: 86.88 %
Validation loss: 0.741691
Validation accuracy: 86.68% 

Epoch 16
-------------------------------
Training loss: 0.883917  [16/3680]
Training loss: 1.389414  [1616/3680]
Training loss: 0.912440  [3216/3680]
Training accuracy: 87.15 %
Validation loss: 0.696325
Validation accuracy: 87.12% 

Epoch 17
-------------------------------
Training loss: 0.987861  [16/3680]
Training loss: 0.395344  [1616/3680]
Training loss: 0.495802  [3216/3680]
Training accuracy: 86.71 %
Validation loss: 0.683575
Validation accuracy: 87.50% 

Epoch 18
-------------------------------
Training loss: 0.747031  [16/3680]
Training loss: 0.709044  [1616/3680]
Training loss: 0.591702  [3216/3680]
Training accuracy: 87.85 %
Validation loss: 0.667741
Validation accuracy: 86.74% 

Epoch 19
-------------------------------
Training loss: 0.614856  [16/3680]
Training loss: 0.721457  [1616/3680]
Training loss: 0.465849  [3216/3680]
Training accuracy: 87.50 %
Validation loss: 0.653393
Validation accuracy: 86.95% 

Epoch 20
-------------------------------
Training loss: 0.786129  [16/3680]
Training loss: 0.501462  [1616/3680]
Training loss: 0.727052  [3216/3680]
Training accuracy: 88.42 %
Validation loss: 0.632026
Validation accuracy: 87.34% 

Epoch 21
-------------------------------
Training loss: 0.870998  [16/3680]
Training loss: 0.616808  [1616/3680]
Training loss: 0.720675  [3216/3680]
Training accuracy: 88.37 %
Validation loss: 0.607613
Validation accuracy: 87.77% 

Epoch 22
-------------------------------
Training loss: 0.693039  [16/3680]
Training loss: 0.710238  [1616/3680]
Training loss: 0.590066  [3216/3680]
Training accuracy: 88.86 %
Validation loss: 0.600419
Validation accuracy: 87.39% 

Epoch 23
-------------------------------
Training loss: 0.700876  [16/3680]
Training loss: 0.529984  [1616/3680]
Training loss: 0.724836  [3216/3680]
Training accuracy: 88.29 %
Validation loss: 0.573820
Validation accuracy: 87.61% 

Epoch 24
-------------------------------
Training loss: 0.719871  [16/3680]
Training loss: 0.534609  [1616/3680]
Training loss: 0.523329  [3216/3680]
Training accuracy: 88.80 %
Validation loss: 0.560659
Validation accuracy: 87.77% 

Epoch 25
-------------------------------
Training loss: 0.324894  [16/3680]
Training loss: 0.577914  [1616/3680]
Training loss: 0.510056  [3216/3680]
Training accuracy: 89.57 %
Validation loss: 0.567506
Validation accuracy: 87.77% 

Epoch 26
-------------------------------
Training loss: 0.453155  [16/3680]
Training loss: 0.783920  [1616/3680]
Training loss: 0.702786  [3216/3680]
Training accuracy: 88.91 %
Validation loss: 0.551964
Validation accuracy: 88.37% 

Epoch 27
-------------------------------
Training loss: 0.727896  [16/3680]
Training loss: 0.591664  [1616/3680]
Training loss: 0.658995  [3216/3680]
Training accuracy: 89.05 %
Validation loss: 0.528284
Validation accuracy: 87.99% 

Epoch 28
-------------------------------
Training loss: 0.820998  [16/3680]
Training loss: 0.709891  [1616/3680]
Training loss: 0.362020  [3216/3680]
Training accuracy: 89.40 %
Validation loss: 0.526309
Validation accuracy: 88.10% 

Epoch 29
-------------------------------
Training loss: 0.451043  [16/3680]
Training loss: 0.458102  [1616/3680]
Training loss: 0.557348  [3216/3680]
Training accuracy: 89.32 %
Validation loss: 0.516843
Validation accuracy: 88.48% 

Epoch 30
-------------------------------
Training loss: 0.362576  [16/3680]
Training loss: 0.632125  [1616/3680]
Training loss: 0.486863  [3216/3680]
Training accuracy: 89.29 %
Validation loss: 0.509587
Validation accuracy: 88.21% 

Epoch 31
-------------------------------
Training loss: 0.682313  [16/3680]
Training loss: 0.454597  [1616/3680]
Training loss: 0.207262  [3216/3680]
Training accuracy: 90.27 %
Validation loss: 0.501152
Validation accuracy: 88.16% 

Epoch 32
-------------------------------
Training loss: 0.388868  [16/3680]
Training loss: 0.789540  [1616/3680]
Training loss: 0.284993  [3216/3680]
Training accuracy: 90.11 %
Validation loss: 0.486374
Validation accuracy: 88.21% 

Epoch 33
-------------------------------
Training loss: 0.736003  [16/3680]
Training loss: 0.415171  [1616/3680]
Training loss: 0.756442  [3216/3680]
Training accuracy: 89.97 %
Validation loss: 0.491870
Validation accuracy: 88.43% 

Epoch 34
-------------------------------
Training loss: 0.633569  [16/3680]
Training loss: 0.466490  [1616/3680]
Training loss: 0.501925  [3216/3680]
Training accuracy: 89.81 %
Validation loss: 0.477621
Validation accuracy: 88.48% 

Early stopping
Done!

Elapsed time: 1724.7954142093658 seconds

Current time: 10:52:17
                         precision    recall  f1-score   support

             Abyssinian       0.73      0.84      0.78        49
       American Bulldog       0.74      0.96      0.83        50
  American pitbull terr       0.80      0.48      0.60        50
           Basset hound       0.98      0.92      0.95        50
                 Beagle       0.89      0.96      0.92        50
                 Bengal       0.67      0.84      0.74        50
                 Birman       0.80      0.80      0.80        50
                 Bombay       0.86      0.95      0.90        44
                  Boxer       0.85      0.88      0.86        50
      British Shorthair       0.91      0.80      0.85        50
              Chihuahua       0.85      0.92      0.88        50
           Egyptian Mau       0.95      0.71      0.81        49
 English cocker spaniel       0.96      0.96      0.96        50
         English setter       0.96      0.94      0.95        50
     German shorthaired       0.83      1.00      0.91        50
         Great pyrenees       0.96      0.92      0.94        50
               Havanese       0.85      0.94      0.90        50
          Japanese chin       0.98      0.96      0.97        50
               Keeshond       0.98      1.00      0.99        50
             Leonberger       0.98      1.00      0.99        50
             Maine Coon       0.83      0.70      0.76        50
     Miniature pinscher       0.94      0.88      0.91        50
           Newfoundland       0.98      1.00      0.99        50
                Persian       0.79      0.88      0.83        50
             Pomeranian       0.98      0.92      0.95        50
                    Pug       0.96      0.92      0.94        50
                Ragdoll       0.77      0.72      0.74        50
           Russian blue       0.90      0.74      0.81        50
          Saint bernard       0.98      0.98      0.98        50
                Samoyed       0.93      1.00      0.96        50
       Scottish terrier       0.91      0.98      0.94        50
              Shiba inu       0.92      0.94      0.93        50
                Siamese       0.92      0.94      0.93        50
                 Sphynx       0.83      0.90      0.87        50
Staffordshire bull terr       0.63      0.53      0.58        45
        Wheaten terrier       0.96      0.90      0.93        50
      Yorkshire terrier       0.98      0.88      0.93        50

               accuracy                           0.88      1837
              macro avg       0.88      0.88      0.88      1837
           weighted avg       0.89      0.88      0.88      1837

Test accuracy: 0.8818726183995645
The metadata of the previous execution is...
{'training_images_percentage': 1, 'epochs': 55, 'learning_rate': 0.001, 'batch_size': 16, 'data_augmentation': 'no', 'subject_driven_technique': 'controlNet', 'number_of_samples': 5, 'images_to_generate': 100, 'FID_threshold': 100, 'check_quality': False, 'path_to_dataset': '../../../../../../work3/s226536/datasets/oxford-iiit-pet', 'DATA_DIR': '../../../../../../work3/s226536/datasets'}

Preparing next execution...
Finished preparing next execution...
