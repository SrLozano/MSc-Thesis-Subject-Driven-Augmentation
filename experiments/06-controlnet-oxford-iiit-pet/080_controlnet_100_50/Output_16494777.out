Downloading https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz to ../../../../../../work3/s226536/datasets/oxford-iiit-pet/images.tar.gz
Extracting ../../../../../../work3/s226536/datasets/oxford-iiit-pet/images.tar.gz to ../../../../../../work3/s226536/datasets/oxford-iiit-pet
Downloading https://thor.robots.ox.ac.uk/datasets/pets/annotations.tar.gz to ../../../../../../work3/s226536/datasets/oxford-iiit-pet/annotations.tar.gz
Extracting ../../../../../../work3/s226536/datasets/oxford-iiit-pet/annotations.tar.gz to ../../../../../../work3/s226536/datasets/oxford-iiit-pet
-------------------------------------
Generating 50 images for breed Abyssinian...

Not using data augmentation
Using cuda device
Epoch 1
-------------------------------
Training loss: 4.078019  [16/3699]
Training loss: 3.375229  [1616/3699]
Training loss: 3.253287  [3216/3699]
Training accuracy: 22.38 %
Validation loss: 3.065602
Validation accuracy: 24.73% 

Epoch 2
-------------------------------
Training loss: 3.115971  [16/3699]
Training loss: 2.893116  [1616/3699]
Training loss: 2.818305  [3216/3699]
Training accuracy: 48.61 %
Validation loss: 2.579546
Validation accuracy: 52.13% 

Epoch 3
-------------------------------
Training loss: 2.707435  [16/3699]
Training loss: 2.479580  [1616/3699]
Training loss: 2.563959  [3216/3699]
Training accuracy: 63.80 %
Validation loss: 2.172939
Validation accuracy: 67.74% 

Epoch 4
-------------------------------
Training loss: 2.342106  [16/3699]
Training loss: 2.022274  [1616/3699]
Training loss: 1.978829  [3216/3699]
Training accuracy: 72.02 %
Validation loss: 1.846381
Validation accuracy: 74.67% 

Epoch 5
-------------------------------
Training loss: 2.193813  [16/3699]
Training loss: 2.069970  [1616/3699]
Training loss: 2.047223  [3216/3699]
Training accuracy: 75.78 %
Validation loss: 1.614189
Validation accuracy: 78.38% 

Epoch 6
-------------------------------
Training loss: 1.650448  [16/3699]
Training loss: 1.541010  [1616/3699]
Training loss: 1.636432  [3216/3699]
Training accuracy: 79.59 %
Validation loss: 1.386555
Validation accuracy: 81.44% 

Epoch 7
-------------------------------
Training loss: 1.568114  [16/3699]
Training loss: 1.722896  [1616/3699]
Training loss: 1.158228  [3216/3699]
Training accuracy: 82.24 %
Validation loss: 1.248869
Validation accuracy: 83.41% 

Epoch 8
-------------------------------
Training loss: 1.571889  [16/3699]
Training loss: 1.613963  [1616/3699]
Training loss: 1.312643  [3216/3699]
Training accuracy: 83.67 %
Validation loss: 1.132031
Validation accuracy: 85.04% 

Epoch 9
-------------------------------
Training loss: 1.593097  [16/3699]
Training loss: 1.635973  [1616/3699]
Training loss: 1.153116  [3216/3699]
Training accuracy: 85.40 %
Validation loss: 1.033613
Validation accuracy: 85.64% 

Epoch 10
-------------------------------
Training loss: 1.267183  [16/3699]
Training loss: 1.363911  [1616/3699]
Training loss: 1.202185  [3216/3699]
Training accuracy: 84.94 %
Validation loss: 0.960085
Validation accuracy: 85.43% 

Epoch 11
-------------------------------
Training loss: 1.089631  [16/3699]
Training loss: 0.857747  [1616/3699]
Training loss: 0.731567  [3216/3699]
Training accuracy: 86.32 %
Validation loss: 0.907492
Validation accuracy: 86.52% 

Epoch 12
-------------------------------
Training loss: 1.117869  [16/3699]
Training loss: 1.134413  [1616/3699]
Training loss: 1.034287  [3216/3699]
Training accuracy: 87.13 %
Validation loss: 0.843226
Validation accuracy: 86.46% 

Epoch 13
-------------------------------
Training loss: 1.210650  [16/3699]
Training loss: 0.615095  [1616/3699]
Training loss: 0.877482  [3216/3699]
Training accuracy: 86.40 %
Validation loss: 0.795330
Validation accuracy: 86.19% 

Epoch 14
-------------------------------
Training loss: 0.803939  [16/3699]
Training loss: 0.970007  [1616/3699]
Training loss: 0.586377  [3216/3699]
Training accuracy: 87.65 %
Validation loss: 0.766318
Validation accuracy: 86.74% 

Epoch 15
-------------------------------
Training loss: 0.661028  [16/3699]
Training loss: 0.930031  [1616/3699]
Training loss: 0.630125  [3216/3699]
Training accuracy: 87.65 %
Validation loss: 0.724692
Validation accuracy: 87.72% 

Epoch 16
-------------------------------
Training loss: 0.842024  [16/3699]
Training loss: 1.318079  [1616/3699]
Training loss: 0.844900  [3216/3699]
Training accuracy: 87.37 %
Validation loss: 0.681080
Validation accuracy: 87.23% 

Epoch 17
-------------------------------
Training loss: 0.763943  [16/3699]
Training loss: 0.870969  [1616/3699]
Training loss: 0.866096  [3216/3699]
Training accuracy: 87.83 %
Validation loss: 0.652970
Validation accuracy: 87.88% 

Epoch 18
-------------------------------
Training loss: 0.572771  [16/3699]
Training loss: 0.419667  [1616/3699]
Training loss: 0.544373  [3216/3699]
Training accuracy: 88.27 %
Validation loss: 0.642233
Validation accuracy: 87.61% 

Epoch 19
-------------------------------
Training loss: 0.550624  [16/3699]
Training loss: 0.710044  [1616/3699]
Training loss: 0.506145  [3216/3699]
Training accuracy: 88.70 %
Validation loss: 0.625670
Validation accuracy: 87.72% 

Epoch 20
-------------------------------
Training loss: 0.715750  [16/3699]
Training loss: 0.651048  [1616/3699]
Training loss: 0.774103  [3216/3699]
Training accuracy: 88.43 %
Validation loss: 0.605172
Validation accuracy: 87.55% 

Epoch 21
-------------------------------
Training loss: 0.720264  [16/3699]
Training loss: 0.582732  [1616/3699]
Training loss: 0.415549  [3216/3699]
Training accuracy: 89.32 %
Validation loss: 0.593606
Validation accuracy: 88.26% 

Epoch 22
-------------------------------
Training loss: 0.633789  [16/3699]
Training loss: 0.742754  [1616/3699]
Training loss: 0.759556  [3216/3699]
Training accuracy: 89.65 %
Validation loss: 0.569930
Validation accuracy: 87.77% 

Epoch 23
-------------------------------
Training loss: 0.475235  [16/3699]
Training loss: 0.758488  [1616/3699]
Training loss: 0.615934  [3216/3699]
Training accuracy: 89.65 %
Validation loss: 0.558469
Validation accuracy: 87.83% 

Epoch 24
-------------------------------
Training loss: 0.551829  [16/3699]
Training loss: 0.671133  [1616/3699]
Training loss: 0.654161  [3216/3699]
Training accuracy: 89.56 %
Validation loss: 0.561255
Validation accuracy: 87.55% 

Epoch 25
-------------------------------
Training loss: 0.654124  [16/3699]
Training loss: 0.506005  [1616/3699]
Training loss: 0.357450  [3216/3699]
Training accuracy: 89.67 %
Validation loss: 0.538477
Validation accuracy: 88.26% 

Epoch 26
-------------------------------
Training loss: 0.422802  [16/3699]
Training loss: 0.519875  [1616/3699]
Training loss: 0.524178  [3216/3699]
Training accuracy: 88.92 %
Validation loss: 0.537462
Validation accuracy: 87.99% 

Early stopping
Done!

Elapsed time: 1432.0601136684418 seconds

Current time: 12:39:58
                         precision    recall  f1-score   support

             Abyssinian       0.74      0.71      0.73        49
       American Bulldog       0.77      0.92      0.84        50
  American pitbull terr       0.79      0.62      0.70        50
           Basset hound       0.96      0.94      0.95        50
                 Beagle       0.94      0.92      0.93        50
                 Bengal       0.75      0.72      0.73        50
                 Birman       0.70      0.80      0.75        50
                 Bombay       0.84      0.95      0.89        44
                  Boxer       0.85      0.88      0.86        50
      British Shorthair       0.81      0.78      0.80        50
              Chihuahua       0.96      0.86      0.91        50
           Egyptian Mau       0.83      0.82      0.82        49
 English cocker spaniel       0.94      0.92      0.93        50
         English setter       0.90      0.94      0.92        50
     German shorthaired       0.83      1.00      0.91        50
         Great pyrenees       0.94      0.94      0.94        50
               Havanese       0.84      0.98      0.91        50
          Japanese chin       0.98      0.96      0.97        50
               Keeshond       0.96      0.98      0.97        50
             Leonberger       0.96      1.00      0.98        50
             Maine Coon       0.74      0.80      0.77        50
     Miniature pinscher       0.98      0.88      0.93        50
           Newfoundland       0.98      0.98      0.98        50
                Persian       0.85      0.82      0.84        50
             Pomeranian       0.98      0.84      0.90        50
                    Pug       0.98      0.90      0.94        50
                Ragdoll       0.80      0.70      0.74        50
           Russian blue       0.74      0.70      0.72        50
          Saint bernard       0.98      0.98      0.98        50
                Samoyed       0.86      1.00      0.93        50
       Scottish terrier       0.91      0.98      0.94        50
              Shiba inu       0.94      0.96      0.95        50
                Siamese       0.89      0.84      0.87        50
                 Sphynx       0.85      0.92      0.88        50
Staffordshire bull terr       0.67      0.62      0.64        45
        Wheaten terrier       1.00      0.90      0.95        50
      Yorkshire terrier       0.98      0.90      0.94        50

               accuracy                           0.88      1837
              macro avg       0.88      0.87      0.87      1837
           weighted avg       0.88      0.88      0.87      1837

Test accuracy: 0.8753402286336418
The metadata of the previous execution is...
{'training_images_percentage': 1, 'epochs': 55, 'learning_rate': 0.001, 'batch_size': 16, 'data_augmentation': 'no', 'subject_driven_technique': 'controlNet', 'number_of_samples': 5, 'images_to_generate': 50, 'FID_threshold': 100, 'check_quality': False, 'path_to_dataset': '../../../../../../work3/s226536/datasets/oxford-iiit-pet', 'DATA_DIR': '../../../../../../work3/s226536/datasets'}

Preparing next execution...
Finished preparing next execution...
