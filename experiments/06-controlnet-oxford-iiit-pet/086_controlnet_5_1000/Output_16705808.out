Not using data augmentation
Using cuda device
Epoch 1
-------------------------------
Training loss: 4.001272  [16/1822]
Training loss: 3.211666  [1616/1822]
Training accuracy: 9.55 %
Validation loss: 3.540371
Validation accuracy: 6.11% 

Epoch 2
-------------------------------
Training loss: 3.659096  [16/1822]
Training loss: 3.328167  [1616/1822]
Training accuracy: 20.36 %
Validation loss: 3.295170
Validation accuracy: 14.08% 

Epoch 3
-------------------------------
Training loss: 3.198894  [16/1822]
Training loss: 3.142654  [1616/1822]
Training accuracy: 32.93 %
Validation loss: 3.079264
Validation accuracy: 24.89% 

Epoch 4
-------------------------------
Training loss: 2.899929  [16/1822]
Training loss: 2.602121  [1616/1822]
Training accuracy: 45.94 %
Validation loss: 2.879543
Validation accuracy: 36.79% 

Epoch 5
-------------------------------
Training loss: 2.661927  [16/1822]
Training loss: 2.547945  [1616/1822]
Training accuracy: 53.46 %
Validation loss: 2.684607
Validation accuracy: 43.34% 

Epoch 6
-------------------------------
Training loss: 2.562602  [16/1822]
Training loss: 2.279487  [1616/1822]
Training accuracy: 60.87 %
Validation loss: 2.533966
Validation accuracy: 48.64% 

Epoch 7
-------------------------------
Training loss: 2.556986  [16/1822]
Training loss: 2.269201  [1616/1822]
Training accuracy: 64.22 %
Validation loss: 2.364639
Validation accuracy: 52.78% 

Epoch 8
-------------------------------
Training loss: 1.904562  [16/1822]
Training loss: 1.959306  [1616/1822]
Training accuracy: 66.85 %
Validation loss: 2.218046
Validation accuracy: 54.26% 

Epoch 9
-------------------------------
Training loss: 2.054933  [16/1822]
Training loss: 1.977903  [1616/1822]
Training accuracy: 70.25 %
Validation loss: 2.109245
Validation accuracy: 57.59% 

Epoch 10
-------------------------------
Training loss: 1.979272  [16/1822]
Training loss: 1.923805  [1616/1822]
Training accuracy: 73.00 %
Validation loss: 2.002788
Validation accuracy: 60.59% 

Epoch 11
-------------------------------
Training loss: 2.160465  [16/1822]
Training loss: 1.720056  [1616/1822]
Training accuracy: 74.64 %
Validation loss: 1.906541
Validation accuracy: 61.24% 

Epoch 12
-------------------------------
Training loss: 1.964056  [16/1822]
Training loss: 1.807624  [1616/1822]
Training accuracy: 76.07 %
Validation loss: 1.800787
Validation accuracy: 62.83% 

Epoch 13
-------------------------------
Training loss: 1.909154  [16/1822]
Training loss: 1.470492  [1616/1822]
Training accuracy: 78.16 %
Validation loss: 1.745155
Validation accuracy: 63.48% 

Epoch 14
-------------------------------
Training loss: 1.586029  [16/1822]
Training loss: 1.246605  [1616/1822]
Training accuracy: 77.66 %
Validation loss: 1.662473
Validation accuracy: 65.17% 

Epoch 15
-------------------------------
Training loss: 1.274631  [16/1822]
Training loss: 1.223440  [1616/1822]
Training accuracy: 79.03 %
Validation loss: 1.604124
Validation accuracy: 65.28% 

Epoch 16
-------------------------------
Training loss: 1.977488  [16/1822]
Training loss: 1.312037  [1616/1822]
Training accuracy: 81.39 %
Validation loss: 1.529598
Validation accuracy: 66.32% 

Epoch 17
-------------------------------
Training loss: 1.100287  [16/1822]
Training loss: 1.144377  [1616/1822]
Training accuracy: 81.12 %
Validation loss: 1.467896
Validation accuracy: 68.29% 

Epoch 18
-------------------------------
Training loss: 1.367316  [16/1822]
Training loss: 1.504035  [1616/1822]
Training accuracy: 82.49 %
Validation loss: 1.453720
Validation accuracy: 68.61% 

Epoch 19
-------------------------------
Training loss: 1.154684  [16/1822]
Training loss: 1.016334  [1616/1822]
Training accuracy: 82.82 %
Validation loss: 1.400292
Validation accuracy: 68.45% 

Epoch 20
-------------------------------
Training loss: 1.302946  [16/1822]
Training loss: 1.111010  [1616/1822]
Training accuracy: 83.59 %
Validation loss: 1.356369
Validation accuracy: 70.52% 

Epoch 21
-------------------------------
Training loss: 1.534340  [16/1822]
Training loss: 1.225258  [1616/1822]
Training accuracy: 83.81 %
Validation loss: 1.326183
Validation accuracy: 70.36% 

Epoch 22
-------------------------------
Training loss: 1.055296  [16/1822]
Training loss: 1.110730  [1616/1822]
Training accuracy: 84.69 %
Validation loss: 1.289368
Validation accuracy: 71.94% 

Epoch 23
-------------------------------
Training loss: 1.376759  [16/1822]
Training loss: 1.350555  [1616/1822]
Training accuracy: 84.91 %
Validation loss: 1.255577
Validation accuracy: 71.89% 

Epoch 24
-------------------------------
Training loss: 0.829454  [16/1822]
Training loss: 0.935420  [1616/1822]
Training accuracy: 83.53 %
Validation loss: 1.233184
Validation accuracy: 71.56% 

Epoch 25
-------------------------------
Training loss: 1.024361  [16/1822]
Training loss: 0.817248  [1616/1822]
Training accuracy: 85.62 %
Validation loss: 1.193162
Validation accuracy: 72.33% 

Epoch 26
-------------------------------
Training loss: 0.806942  [16/1822]
Training loss: 1.028768  [1616/1822]
Training accuracy: 86.39 %
Validation loss: 1.164116
Validation accuracy: 74.02% 

Epoch 27
-------------------------------
Training loss: 1.108176  [16/1822]
Training loss: 0.927106  [1616/1822]
Training accuracy: 85.57 %
Validation loss: 1.164835
Validation accuracy: 73.14% 

Epoch 28
-------------------------------
Training loss: 0.925685  [16/1822]
Training loss: 0.660261  [1616/1822]
Training accuracy: 86.17 %
Validation loss: 1.104223
Validation accuracy: 74.29% 

Epoch 29
-------------------------------
Training loss: 0.841662  [16/1822]
Training loss: 1.031878  [1616/1822]
Training accuracy: 86.17 %
Validation loss: 1.123408
Validation accuracy: 72.60% 

Epoch 30
-------------------------------
Training loss: 1.106632  [16/1822]
Training loss: 0.874517  [1616/1822]
Training accuracy: 87.76 %
Validation loss: 1.083511
Validation accuracy: 73.47% 

Epoch 31
-------------------------------
Training loss: 0.708516  [16/1822]
Training loss: 0.616875  [1616/1822]
Training accuracy: 86.99 %
Validation loss: 1.078935
Validation accuracy: 74.78% 

Epoch 32
-------------------------------
Training loss: 1.097438  [16/1822]
Training loss: 0.866234  [1616/1822]
Training accuracy: 86.83 %
Validation loss: 1.075954
Validation accuracy: 73.74% 

Epoch 33
-------------------------------
Training loss: 1.021668  [16/1822]
Training loss: 0.917676  [1616/1822]
Training accuracy: 86.77 %
Validation loss: 1.035782
Validation accuracy: 74.95% 

Epoch 34
-------------------------------
Training loss: 0.567018  [16/1822]
Training loss: 0.572876  [1616/1822]
Training accuracy: 86.99 %
Validation loss: 1.024778
Validation accuracy: 74.62% 

Epoch 35
-------------------------------
Training loss: 0.975133  [16/1822]
Training loss: 1.032659  [1616/1822]
Training accuracy: 87.87 %
Validation loss: 0.986893
Validation accuracy: 75.82% 

Epoch 36
-------------------------------
Training loss: 0.682974  [16/1822]
Training loss: 0.736497  [1616/1822]
Training accuracy: 88.91 %
Validation loss: 0.990500
Validation accuracy: 75.93% 

Epoch 37
-------------------------------
Training loss: 0.644032  [16/1822]
Training loss: 0.884122  [1616/1822]
Training accuracy: 88.42 %
Validation loss: 0.977078
Validation accuracy: 75.93% 

Epoch 38
-------------------------------
Training loss: 0.881175  [16/1822]
Training loss: 0.669246  [1616/1822]
Training accuracy: 87.76 %
Validation loss: 0.959230
Validation accuracy: 76.53% 

Epoch 39
-------------------------------
Training loss: 0.918601  [16/1822]
Training loss: 1.244848  [1616/1822]
Training accuracy: 89.24 %
Validation loss: 0.940711
Validation accuracy: 77.02% 

Epoch 40
-------------------------------
Training loss: 0.544179  [16/1822]
Training loss: 0.710579  [1616/1822]
Training accuracy: 88.69 %
Validation loss: 0.952265
Validation accuracy: 75.33% 

Epoch 41
-------------------------------
Training loss: 0.470988  [16/1822]
Training loss: 0.741531  [1616/1822]
Training accuracy: 87.98 %
Validation loss: 0.920890
Validation accuracy: 78.06% 

Epoch 42
-------------------------------
Training loss: 1.079066  [16/1822]
Training loss: 0.444310  [1616/1822]
Training accuracy: 88.80 %
Validation loss: 0.927335
Validation accuracy: 76.69% 

Epoch 43
-------------------------------
Training loss: 0.811791  [16/1822]
Training loss: 0.842815  [1616/1822]
Training accuracy: 89.24 %
Validation loss: 0.909206
Validation accuracy: 76.69% 

Epoch 44
-------------------------------
Training loss: 0.627037  [16/1822]
Training loss: 0.656410  [1616/1822]
Training accuracy: 89.02 %
Validation loss: 0.904623
Validation accuracy: 77.35% 

Epoch 45
-------------------------------
Training loss: 0.724961  [16/1822]
Training loss: 0.800326  [1616/1822]
Training accuracy: 90.50 %
Validation loss: 0.903348
Validation accuracy: 77.18% 

Epoch 46
-------------------------------
Training loss: 0.778939  [16/1822]
Training loss: 0.720941  [1616/1822]
Training accuracy: 89.63 %
Validation loss: 0.915132
Validation accuracy: 76.53% 

Early stopping
Done!

Elapsed time: 2075.074120759964 seconds

Current time: 01:20:46
                         precision    recall  f1-score   support

             Abyssinian       0.59      0.55      0.57        49
       American Bulldog       0.76      0.82      0.79        50
  American pitbull terr       0.54      0.14      0.22        50
           Basset hound       0.88      0.90      0.89        50
                 Beagle       0.91      0.84      0.87        50
                 Bengal       0.80      0.16      0.27        50
                 Birman       0.41      0.52      0.46        50
                 Bombay       0.94      0.66      0.77        44
                  Boxer       0.89      0.80      0.84        50
      British Shorthair       0.55      0.76      0.64        50
              Chihuahua       0.97      0.64      0.77        50
           Egyptian Mau       0.56      0.90      0.69        49
 English cocker spaniel       0.86      0.86      0.86        50
         English setter       0.91      0.86      0.89        50
     German shorthaired       0.67      1.00      0.80        50
         Great pyrenees       0.86      0.98      0.92        50
               Havanese       0.94      0.66      0.78        50
          Japanese chin       0.98      0.88      0.93        50
               Keeshond       0.91      1.00      0.95        50
             Leonberger       0.89      0.96      0.92        50
             Maine Coon       0.85      0.46      0.60        50
     Miniature pinscher       1.00      0.66      0.80        50
           Newfoundland       0.86      1.00      0.93        50
                Persian       0.79      0.76      0.78        50
             Pomeranian       1.00      0.76      0.86        50
                    Pug       1.00      0.88      0.94        50
                Ragdoll       0.34      0.28      0.31        50
           Russian blue       0.65      0.62      0.63        50
          Saint bernard       0.93      1.00      0.96        50
                Samoyed       0.83      0.98      0.90        50
       Scottish terrier       0.84      0.94      0.89        50
              Shiba inu       0.91      0.96      0.93        50
                Siamese       0.64      0.86      0.74        50
                 Sphynx       0.87      0.78      0.82        50
Staffordshire bull terr       0.44      0.84      0.58        45
        Wheaten terrier       0.55      0.96      0.70        50
      Yorkshire terrier       1.00      0.68      0.81        50

               accuracy                           0.77      1837
              macro avg       0.79      0.77      0.76      1837
           weighted avg       0.79      0.77      0.76      1837

Test accuracy: 0.7653783342406096
