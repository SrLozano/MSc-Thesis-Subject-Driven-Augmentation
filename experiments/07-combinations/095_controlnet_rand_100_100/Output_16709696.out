Using randaugment for data augmentation
Using cuda device
Epoch 1
-------------------------------
Training loss: 4.398077  [16/6955]
Training loss: 3.666875  [1616/6955]
Training loss: 3.430452  [3216/6955]
Training loss: 3.174611  [4816/6955]
Training loss: 3.157474  [6416/6955]
Training accuracy: 29.73 %
Validation loss: 2.914903
Validation accuracy: 35.64% 

Epoch 2
-------------------------------
Training loss: 2.888715  [16/6955]
Training loss: 2.852044  [1616/6955]
Training loss: 2.543816  [3216/6955]
Training loss: 2.769433  [4816/6955]
Training loss: 2.436394  [6416/6955]
Training accuracy: 52.57 %
Validation loss: 2.270065
Validation accuracy: 60.48% 

Epoch 3
-------------------------------
Training loss: 2.499757  [16/6955]
Training loss: 2.540059  [1616/6955]
Training loss: 2.258278  [3216/6955]
Training loss: 2.177224  [4816/6955]
Training loss: 2.402435  [6416/6955]
Training accuracy: 63.54 %
Validation loss: 1.812302
Validation accuracy: 71.34% 

Epoch 4
-------------------------------
Training loss: 1.806717  [16/6955]
Training loss: 2.182042  [1616/6955]
Training loss: 2.263196  [3216/6955]
Training loss: 1.640213  [4816/6955]
Training loss: 1.608845  [6416/6955]
Training accuracy: 69.14 %
Validation loss: 1.485877
Validation accuracy: 76.64% 

Epoch 5
-------------------------------
Training loss: 1.910100  [16/6955]
Training loss: 1.681960  [1616/6955]
Training loss: 1.607195  [3216/6955]
Training loss: 1.502426  [4816/6955]
Training loss: 1.631680  [6416/6955]
Training accuracy: 72.26 %
Validation loss: 1.261750
Validation accuracy: 81.06% 

Epoch 6
-------------------------------
Training loss: 1.851932  [16/6955]
Training loss: 1.318716  [1616/6955]
Training loss: 1.603297  [3216/6955]
Training loss: 1.452829  [4816/6955]
Training loss: 1.528204  [6416/6955]
Training accuracy: 73.57 %
Validation loss: 1.116015
Validation accuracy: 82.26% 

Epoch 7
-------------------------------
Training loss: 1.343977  [16/6955]
Training loss: 1.115599  [1616/6955]
Training loss: 1.637370  [3216/6955]
Training loss: 1.101319  [4816/6955]
Training loss: 1.320947  [6416/6955]
Training accuracy: 74.41 %
Validation loss: 1.013122
Validation accuracy: 82.48% 

Epoch 8
-------------------------------
Training loss: 1.264711  [16/6955]
Training loss: 1.226500  [1616/6955]
Training loss: 1.239153  [3216/6955]
Training loss: 1.121953  [4816/6955]
Training loss: 1.010762  [6416/6955]
Training accuracy: 76.13 %
Validation loss: 0.896571
Validation accuracy: 84.33% 

Epoch 9
-------------------------------
Training loss: 1.348068  [16/6955]
Training loss: 1.295354  [1616/6955]
Training loss: 1.010108  [3216/6955]
Training loss: 1.473399  [4816/6955]
Training loss: 1.299397  [6416/6955]
Training accuracy: 77.54 %
Validation loss: 0.835938
Validation accuracy: 84.39% 

Epoch 10
-------------------------------
Training loss: 1.178362  [16/6955]
Training loss: 1.661083  [1616/6955]
Training loss: 0.985779  [3216/6955]
Training loss: 0.924013  [4816/6955]
Training loss: 1.421707  [6416/6955]
Training accuracy: 77.80 %
Validation loss: 0.768016
Validation accuracy: 85.37% 

Epoch 11
-------------------------------
Training loss: 0.858935  [16/6955]
Training loss: 1.089378  [1616/6955]
Training loss: 0.774976  [3216/6955]
Training loss: 0.814666  [4816/6955]
Training loss: 1.411391  [6416/6955]
Training accuracy: 78.68 %
Validation loss: 0.737079
Validation accuracy: 85.48% 

Epoch 12
-------------------------------
Training loss: 0.863671  [16/6955]
Training loss: 1.281813  [1616/6955]
Training loss: 1.110408  [3216/6955]
Training loss: 0.932791  [4816/6955]
Training loss: 0.955290  [6416/6955]
Training accuracy: 78.50 %
Validation loss: 0.700493
Validation accuracy: 85.64% 

Epoch 13
-------------------------------
Training loss: 1.124665  [16/6955]
Training loss: 1.035785  [1616/6955]
Training loss: 1.014487  [3216/6955]
Training loss: 0.650055  [4816/6955]
Training loss: 0.912276  [6416/6955]
Training accuracy: 78.86 %
Validation loss: 0.658384
Validation accuracy: 85.97% 

Epoch 14
-------------------------------
Training loss: 1.172718  [16/6955]
Training loss: 0.680723  [1616/6955]
Training loss: 0.982849  [3216/6955]
Training loss: 0.888213  [4816/6955]
Training loss: 0.979496  [6416/6955]
Training accuracy: 79.38 %
Validation loss: 0.635952
Validation accuracy: 86.46% 

Epoch 15
-------------------------------
Training loss: 0.977094  [16/6955]
Training loss: 1.049761  [1616/6955]
Training loss: 0.799391  [3216/6955]
Training loss: 0.869732  [4816/6955]
Training loss: 0.843162  [6416/6955]
Training accuracy: 79.18 %
Validation loss: 0.611310
Validation accuracy: 87.01% 

Epoch 16
-------------------------------
Training loss: 1.204906  [16/6955]
Training loss: 0.957039  [1616/6955]
Training loss: 0.701369  [3216/6955]
Training loss: 0.679823  [4816/6955]
Training loss: 1.091403  [6416/6955]
Training accuracy: 80.26 %
Validation loss: 0.585559
Validation accuracy: 86.79% 

Epoch 17
-------------------------------
Training loss: 1.025993  [16/6955]
Training loss: 0.881906  [1616/6955]
Training loss: 1.049654  [3216/6955]
Training loss: 0.492832  [4816/6955]
Training loss: 0.791101  [6416/6955]
Training accuracy: 79.53 %
Validation loss: 0.571649
Validation accuracy: 86.19% 

Epoch 18
-------------------------------
Training loss: 0.808936  [16/6955]
Training loss: 0.682814  [1616/6955]
Training loss: 0.871457  [3216/6955]
Training loss: 1.151965  [4816/6955]
Training loss: 0.804501  [6416/6955]
Training accuracy: 80.73 %
Validation loss: 0.550817
Validation accuracy: 87.28% 

Epoch 19
-------------------------------
Training loss: 0.679596  [16/6955]
Training loss: 0.943901  [1616/6955]
Training loss: 1.255242  [3216/6955]
Training loss: 0.936114  [4816/6955]
Training loss: 0.775873  [6416/6955]
Training accuracy: 81.01 %
Validation loss: 0.539856
Validation accuracy: 87.61% 

Epoch 20
-------------------------------
Training loss: 0.837135  [16/6955]
Training loss: 1.118828  [1616/6955]
Training loss: 0.749135  [3216/6955]
Training loss: 1.104572  [4816/6955]
Training loss: 0.542106  [6416/6955]
Training accuracy: 80.66 %
Validation loss: 0.533589
Validation accuracy: 87.17% 

Epoch 21
-------------------------------
Training loss: 0.854054  [16/6955]
Training loss: 0.726699  [1616/6955]
Training loss: 0.747785  [3216/6955]
Training loss: 1.128941  [4816/6955]
Training loss: 0.837477  [6416/6955]
Training accuracy: 80.83 %
Validation loss: 0.527418
Validation accuracy: 87.39% 

Epoch 22
-------------------------------
Training loss: 0.935371  [16/6955]
Training loss: 0.456916  [1616/6955]
Training loss: 0.583652  [3216/6955]
Training loss: 0.538169  [4816/6955]
Training loss: 0.655708  [6416/6955]
Training accuracy: 80.83 %
Validation loss: 0.501897
Validation accuracy: 86.95% 

Epoch 23
-------------------------------
Training loss: 0.799472  [16/6955]
Training loss: 0.364474  [1616/6955]
Training loss: 1.017075  [3216/6955]
Training loss: 1.001307  [4816/6955]
Training loss: 0.496655  [6416/6955]
Training accuracy: 81.34 %
Validation loss: 0.496473
Validation accuracy: 87.77% 

Epoch 24
-------------------------------
Training loss: 0.713735  [16/6955]
Training loss: 0.658596  [1616/6955]
Training loss: 0.836804  [3216/6955]
Training loss: 0.768590  [4816/6955]
Training loss: 0.930299  [6416/6955]
Training accuracy: 81.57 %
Validation loss: 0.493289
Validation accuracy: 87.28% 

Epoch 25
-------------------------------
Training loss: 0.554681  [16/6955]
Training loss: 0.967231  [1616/6955]
Training loss: 0.592702  [3216/6955]
Training loss: 1.125281  [4816/6955]
Training loss: 0.461251  [6416/6955]
Training accuracy: 81.90 %
Validation loss: 0.497581
Validation accuracy: 87.94% 

Epoch 26
-------------------------------
Training loss: 0.523553  [16/6955]
Training loss: 0.560097  [1616/6955]
Training loss: 0.512876  [3216/6955]
Training loss: 0.594510  [4816/6955]
Training loss: 0.617719  [6416/6955]
Training accuracy: 81.45 %
Validation loss: 0.485516
Validation accuracy: 87.94% 

Epoch 27
-------------------------------
Training loss: 0.625452  [16/6955]
Training loss: 0.287701  [1616/6955]
Training loss: 1.002002  [3216/6955]
Training loss: 0.469952  [4816/6955]
Training loss: 0.671594  [6416/6955]
Training accuracy: 81.48 %
Validation loss: 0.477153
Validation accuracy: 87.50% 

Epoch 28
-------------------------------
Training loss: 0.744008  [16/6955]
Training loss: 0.847579  [1616/6955]
Training loss: 0.817197  [3216/6955]
Training loss: 0.788679  [4816/6955]
Training loss: 0.678768  [6416/6955]
Training accuracy: 82.13 %
Validation loss: 0.471596
Validation accuracy: 87.06% 

Epoch 29
-------------------------------
Training loss: 0.817678  [16/6955]
Training loss: 0.477691  [1616/6955]
Training loss: 0.694484  [3216/6955]
Training loss: 0.722448  [4816/6955]
Training loss: 1.007848  [6416/6955]
Training accuracy: 81.90 %
Validation loss: 0.465919
Validation accuracy: 87.61% 

Epoch 30
-------------------------------
Training loss: 1.027574  [16/6955]
Training loss: 0.372809  [1616/6955]
Training loss: 0.538353  [3216/6955]
Training loss: 0.429480  [4816/6955]
Training loss: 0.670561  [6416/6955]
Training accuracy: 81.78 %
Validation loss: 0.446594
Validation accuracy: 87.99% 

Epoch 31
-------------------------------
Training loss: 0.692247  [16/6955]
Training loss: 0.643348  [1616/6955]
Training loss: 0.437822  [3216/6955]
Training loss: 0.550766  [4816/6955]
Training loss: 0.450651  [6416/6955]
Training accuracy: 82.54 %
Validation loss: 0.444763
Validation accuracy: 88.05% 

Epoch 32
-------------------------------
Training loss: 0.621626  [16/6955]
Training loss: 1.174690  [1616/6955]
Training loss: 0.597710  [3216/6955]
Training loss: 0.483651  [4816/6955]
Training loss: 0.660994  [6416/6955]
Training accuracy: 82.06 %
Validation loss: 0.446754
Validation accuracy: 87.72% 

Epoch 33
-------------------------------
Training loss: 0.570560  [16/6955]
Training loss: 0.413962  [1616/6955]
Training loss: 0.376898  [3216/6955]
Training loss: 0.765237  [4816/6955]
Training loss: 0.624178  [6416/6955]
Training accuracy: 82.75 %
Validation loss: 0.439973
Validation accuracy: 87.55% 

Epoch 34
-------------------------------
Training loss: 0.239256  [16/6955]
Training loss: 0.867702  [1616/6955]
Training loss: 1.148539  [3216/6955]
Training loss: 0.590824  [4816/6955]
Training loss: 0.627118  [6416/6955]
Training accuracy: 82.30 %
Validation loss: 0.437107
Validation accuracy: 88.26% 

Epoch 35
-------------------------------
Training loss: 1.009912  [16/6955]
Training loss: 0.619007  [1616/6955]
Training loss: 0.850155  [3216/6955]
Training loss: 0.680889  [4816/6955]
Training loss: 0.997558  [6416/6955]
Training accuracy: 82.23 %
Validation loss: 0.449920
Validation accuracy: 87.83% 

Epoch 36
-------------------------------
Training loss: 0.577901  [16/6955]
Training loss: 1.148869  [1616/6955]
Training loss: 0.617391  [3216/6955]
Training loss: 0.601907  [4816/6955]
Training loss: 0.749844  [6416/6955]
Training accuracy: 82.01 %
Validation loss: 0.434155
Validation accuracy: 88.32% 

Epoch 37
-------------------------------
Training loss: 0.566171  [16/6955]
Training loss: 0.544607  [1616/6955]
Training loss: 0.828391  [3216/6955]
Training loss: 0.545651  [4816/6955]
Training loss: 0.427420  [6416/6955]
Training accuracy: 82.53 %
Validation loss: 0.426668
Validation accuracy: 88.59% 

Epoch 38
-------------------------------
Training loss: 0.661784  [16/6955]
Training loss: 0.267826  [1616/6955]
Training loss: 0.765302  [3216/6955]
Training loss: 0.625645  [4816/6955]
Training loss: 0.857668  [6416/6955]
Training accuracy: 82.42 %
Validation loss: 0.423517
Validation accuracy: 88.37% 

Epoch 39
-------------------------------
Training loss: 0.713914  [16/6955]
Training loss: 0.734681  [1616/6955]
Training loss: 0.417077  [3216/6955]
Training loss: 1.128749  [4816/6955]
Training loss: 0.808632  [6416/6955]
Training accuracy: 82.49 %
Validation loss: 0.431726
Validation accuracy: 88.10% 

Epoch 40
-------------------------------
Training loss: 0.681854  [16/6955]
Training loss: 0.699217  [1616/6955]
Training loss: 0.231616  [3216/6955]
Training loss: 0.535326  [4816/6955]
Training loss: 0.944045  [6416/6955]
Training accuracy: 83.67 %
Validation loss: 0.433238
Validation accuracy: 87.77% 

Epoch 41
-------------------------------
Training loss: 0.652862  [16/6955]
Training loss: 0.569007  [1616/6955]
Training loss: 0.812529  [3216/6955]
Training loss: 0.570421  [4816/6955]
Training loss: 0.895953  [6416/6955]
Training accuracy: 83.38 %
Validation loss: 0.425508
Validation accuracy: 87.99% 

Epoch 42
-------------------------------
Training loss: 0.523962  [16/6955]
Training loss: 0.795406  [1616/6955]
Training loss: 0.544452  [3216/6955]
Training loss: 0.549299  [4816/6955]
Training loss: 0.639989  [6416/6955]
Training accuracy: 82.90 %
Validation loss: 0.411142
Validation accuracy: 88.26% 

Early stopping
Done!

Elapsed time: 5194.510998010635 seconds

Current time: 13:46:23
                         precision    recall  f1-score   support

             Abyssinian       0.88      0.76      0.81        49
       American Bulldog       0.84      0.94      0.89        50
  American pitbull terr       0.73      0.60      0.66        50
           Basset hound       0.96      0.96      0.96        50
                 Beagle       0.96      0.90      0.93        50
                 Bengal       0.75      0.78      0.76        50
                 Birman       0.68      0.84      0.75        50
                 Bombay       0.76      0.93      0.84        44
                  Boxer       0.84      0.86      0.85        50
      British Shorthair       0.80      0.78      0.79        50
              Chihuahua       0.96      0.86      0.91        50
           Egyptian Mau       0.85      0.84      0.85        49
 English cocker spaniel       0.94      0.94      0.94        50
         English setter       0.96      0.98      0.97        50
     German shorthaired       0.83      1.00      0.91        50
         Great pyrenees       0.94      0.96      0.95        50
               Havanese       0.81      0.96      0.88        50
          Japanese chin       0.98      0.94      0.96        50
               Keeshond       0.96      1.00      0.98        50
             Leonberger       1.00      0.98      0.99        50
             Maine Coon       0.81      0.70      0.75        50
     Miniature pinscher       0.98      0.90      0.94        50
           Newfoundland       0.98      1.00      0.99        50
                Persian       0.84      0.84      0.84        50
             Pomeranian       0.98      0.92      0.95        50
                    Pug       0.96      0.92      0.94        50
                Ragdoll       0.70      0.64      0.67        50
           Russian blue       0.86      0.64      0.74        50
          Saint bernard       0.92      0.96      0.94        50
                Samoyed       0.89      1.00      0.94        50
       Scottish terrier       0.93      1.00      0.96        50
              Shiba inu       0.92      0.96      0.94        50
                Siamese       0.92      0.88      0.90        50
                 Sphynx       0.89      0.94      0.91        50
Staffordshire bull terr       0.65      0.69      0.67        45
        Wheaten terrier       0.98      0.90      0.94        50
      Yorkshire terrier       0.98      0.84      0.90        50

               accuracy                           0.88      1837
              macro avg       0.88      0.88      0.88      1837
           weighted avg       0.88      0.88      0.88      1837

Test accuracy: 0.8796951551442569
