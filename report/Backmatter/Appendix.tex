\chapter{Hardware specifications} \label{APHardware}

An NVIDIA A100 graphics card with the following characteristics shown in table \ref{table:TableHardware} has been used to develop this work.

\vspace{25pt}

\begin{table}[ht]
\centering
\begin{tabular}{|>{\columncolor[HTML]{BFBFBF}}l |l|}
\hline
\textbf{Name} & \cellcolor[HTML]{FFFFFF}Tesla A100-PCIE \\ \hline
\textbf{Year} & 2020 \\ \hline
\textbf{Architecture} & GA100   (Ampere) \\ \hline
\textbf{CUDA capability} & 8.0 \\ \hline
\textbf{CUDA cores} & 6912 \\ \hline
\textbf{Clock MHz} & 1410 \\ \hline
\textbf{Memory GiB} & 39.59 \\ \hline
\textbf{SP peak GFlops} & 19492 \\ \hline
\textbf{DP peak GFlops} & 9746 \\ \hline
\textbf{Peak GB/s} & 1555 \\ \hline
\end{tabular}
\caption{\textbf{Specifications of the NVIDIA A100 GPUs used in this work} \cite{HPCDTU}}
\label{table:TableHardware}
\end{table}

\chapter{Software enviroment} \label{APSoftware}

The software tools used throughout the development of this work are shown in table \ref{APSoftware}.

\vspace{25pt}

\begin{table}[ht]
\centering
\begin{tabular}{|l|l|}
\hline
\rowcolor[HTML]{BFBFBF} 
\textbf{Tool} & \textbf{Version} \\ \hline
\rowcolor[HTML]{FFFFFF} 
Python & 3.8.13 \\ \hline
\rowcolor[HTML]{FFFFFF} 
PyTorch & 2.0.1 \\ \hline
\rowcolor[HTML]{FFFFFF} 
Torchvision & 0.15.2 \\ \hline
\rowcolor[HTML]{FFFFFF} 
Hugging Face Diffusers & 0.16.1 \\ \hline
\rowcolor[HTML]{FFFFFF} 
xFormers & 0.0.19 \\ \hline
\rowcolor[HTML]{FFFFFF} 
Transformers & 4.28.1 \\ \hline
\rowcolor[HTML]{FFFFFF} 
Numpy & 1.24.2 \\ \hline
\rowcolor[HTML]{FFFFFF} 
Scipy & 1.10.0 \\ \hline
\rowcolor[HTML]{FFFFFF} 
Scikit-learn & 1.2.2 \\ \hline
\rowcolor[HTML]{FFFFFF} 
Pandas & 1.5.3 \\ \hline
\rowcolor[HTML]{FFFFFF} 
OpenCV & 4.7.0.72 \\ \hline
\rowcolor[HTML]{FFFFFF} 
Pillow & 9.4.0 \\ \hline
\rowcolor[HTML]{FFFFFF} 
Seaborn & 0.12.2 \\ \hline
\rowcolor[HTML]{FFFFFF} 
Matplotlib & 3.7.1 \\ \hline
\end{tabular}
\caption{\textbf{Versions of the software tools used in the project}}
\label{table:TableHSoftware}
\end{table}

\chapter{Rigour and reproducibility} \label{rigour}

All experiments in this study have been carried out with a high degree of rigour, employing meticulous methodologies and protocols. The primary objective has been to minimise the stochastic effects inherent in experimentation within Deep Learning. Measures have been implemented to enhance the reproducibility of the experiments.

Throughout this research, multiple sets of images have been employed as input for models and techniques that are to be replicated and compared. To ensure fair comparisons, the real images utilised for customising the text-to-image models are consistent across all subject-driven approaches. It should be noted that the selection of these images is initially completely random. Conversely, the subsets of training images remain constant across all tests within each experiment. Furthermore, the tests are executed at least twice to mitigate stochastic effects. However, specific results presented in \ref{sec: results} still exhibit instabilities. Due to the substantial computational demands of the tests, running them more times has been unfeasible from the perspective of time and energy efficiency.

To guarantee the reproducibility of the experiments, the project code has been published on GitHub\footnote{\href{https://github.com/SrLozano/MSc-thesis}{https://github.com/SrLozano/MSc-thesis}}. The entire development process has been recorded using version control, enabling exploration of the code to replicate the experiments or expand upon the proposed data augmentation pipeline outlined in the paper.

In short, we underline the commitment to ensure the results are as rigorous and reproducible as possible.